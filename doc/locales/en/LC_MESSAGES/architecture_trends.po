# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2025, dahu feng
# This file is distributed under the same license as the npu-sim package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2025.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: npu-sim \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-12-01 18:33+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.17.0\n"

#: ../../architecture_trends/convergence.rst:2
msgid "架构发展趋势"
msgstr "Architecture Development Trends"

#: ../../architecture_trends/convergence.rst:4
#: ../../architecture_trends/product_landscape.rst:4
msgid "导读"
msgstr "Introduction"

#: ../../architecture_trends/convergence.rst:6
msgid ""
"AI芯片架构的演进展现出一条清晰的轨迹：传统的控制流与数据流两种范式，正在走向融合。控制流架构为了效率，不断引入数据流思想；数据流架构为了通用性，也在增强可编程能力。最终的目标都是构建一个能高效执行主流AI计算，又具备足够灵活性以适应未来算法演进的"
" **混合式、异构** 的计算平台。"
msgstr ""
"The evolution of AI chip architectures shows a clear trajectory: the two traditional paradigms of control flow and data flow are converging. For efficiency, control flow architectures are continuously incorporating data flow concepts; for versatility, data flow architectures are enhancing their programmability. The ultimate goal is to build a **hybrid, heterogeneous** computing platform that can efficiently execute mainstream AI computations while maintaining sufficient flexibility to adapt to future algorithmic advancements."

#: ../../architecture_trends/convergence.rst:9
msgid "架构设计的共同趋势"
msgstr "Common Trends in Architecture Design"

#: ../../architecture_trends/convergence.rst:11
msgid ""
"**片上内存成为芯片性能重要指标**：所有架构都在不遗余力地 "
"**增大片上SRAM的容量和带宽**。无论是GPU的共享内存/L1/L2缓存、IPU/Cerebras的分布式本地SRAM，还是SambaNova的PMU，其目的都是为了将数据尽可能地留在片上，实现极致的数据复用，这是对抗“内存墙”的有效手段。"
msgstr ""
"**On-chip Memory Becomes a Critical Indicator of Chip Performance**: All architectures are making relentless efforts to **increase the capacity and bandwidth of on-chip SRAM**. Whether it's GPU's shared memory/L1/L2 caches, IPU/Cerebras's distributed local SRAM, or SambaNova's PMU, the goal is to keep data on-chip as much as possible to achieve maximum data reuse—an effective approach to combat the \"memory wall.\""

#: ../../architecture_trends/convergence.rst:13
msgid ""
"**显式数据移动成为主流**：硬件自动管理的透明缓存机制正在被 "
"**由编译器或软件控制的显式数据搬运** 所取代或补充。NVIDIA "
"Hopper的 **TMA**、IPU的 **BSP模型**、数据流架构天然的 "
"**数据流转**，都体现了这一趋势。显式控制能带来更高的性能可预测性和更优的数据搬运效率。"
msgstr ""
"**Explicit Data Movement Becomes Mainstream**: Hardware-managed transparent caching mechanisms are being replaced or supplemented by **explicit data transfer controlled by compilers or software**. NVIDIA Hopper's **TMA**, IPU's **BSP model**, and the inherent **data flow** of data flow architectures all reflect this trend. Explicit control delivers higher performance predictability and superior data transfer efficiency."

#: ../../architecture_trends/convergence.rst:15
msgid ""
"**编译器成为核心**：硬件变得越来越异构和专用，手动优化的难度急剧增大。无论是Google的 "
"**XLA**、SambaNova的 **RDU编译器**，还是Graphcore的 **Poplar**，亦或是NVIDIA生态中的 "
"**Triton**，它们的核心任务都是将高层计算图 **自动地** 映射、切分、调度到底层异构硬件上，并规划最优的数据流动路径。"
msgstr ""
"**Compilers Become the Core**: As hardware becomes increasingly heterogeneous and specialized, the difficulty of manual optimization has surged dramatically. Whether it's Google's **XLA**, SambaNova's **RDU Compiler**, Graphcore's **Poplar**, or **Triton** in the NVIDIA ecosystem, their core mission is to **automatically** map, partition, and schedule high-level computation graphs onto underlying heterogeneous hardware, while planning optimal data flow paths."

#: ../../architecture_trends/convergence.rst:17
msgid "**异构与专用单元硬件**：通用计算单元已无法满足AI的性能需求。架构普遍采用异构设计，将不同任务交给最高效的硬件处理。这包括："
msgstr ""
"**Heterogeneous and Specialized Hardware Units**: General-purpose computing units can no longer meet the performance demands of AI. Architectures generally adopt heterogeneous designs, assigning different tasks to the most efficient hardware. This includes:"

#: ../../architecture_trends/convergence.rst:19
msgid "**张量计算单元**：GPU的Tensor Core、TPU的脉动阵列、SambaNova的PCU。"
msgstr "**Tensor Computing Units**: GPU's Tensor Core, TPU's Systolic Array, SambaNova's PCU."

#: ../../architecture_trends/convergence.rst:20
msgid "**控制与标量单元**：可编程的RISC-V核心（如Tenstorrent）、GPU的CUDA Core、TPU的VPU。"
msgstr "**Control and Scalar Units**: Programmable RISC-V cores (e.g., Tenstorrent), GPU's CUDA Core, TPU's VPU."

#: ../../architecture_trends/convergence.rst:21
msgid "**数据搬运与处理单元**：NVIDIA的TMA、各种DMA引擎、内存控制器、编解码单元等。"
msgstr "**Data Transfer and Processing Units**: NVIDIA's TMA, various DMA engines, memory controllers, codec units, etc."

#: ../../architecture_trends/convergence.rst:24
msgid "技术路线的相互借鉴"
msgstr "Mutual Learning Across Technical Routes"

#: ../../architecture_trends/convergence.rst:26
msgid "**GPU正在“数据流化”**："
msgstr "**GPUs Are Becoming \"Data-Flow-Enabled\"**:"

#: ../../architecture_trends/convergence.rst:28
msgid "**从算力核心看**：引入 **Tensor Core**，将最核心的矩阵运算交由专用的数据流引擎处理。"
msgstr "**From the Perspective of Compute Cores**: Introduction of **Tensor Cores**, which offload core matrix operations to specialized data flow engines."

#: ../../architecture_trends/convergence.rst:29
msgid "**从数据移动看**：引入 **TMA**，从隐式的缓存管理走向显式的异步数据块搬运。"
msgstr "**From the Perspective of Data Movement**: Introduction of **TMA**, shifting from implicit cache management to explicit asynchronous block data transfer."

#: ../../architecture_trends/convergence.rst:30
msgid ""
"**从编程模型看**：**CUDA Graph** 允许将一系列Kernel调用预先定义成一个静态图，减少了运行时的调度开销；**Triton**"
" 等语言则让开发者能以更接近数据流（块/Tile级别）的抽象来编写高性能算子。"
msgstr ""
"**From the Perspective of Programming Models**: **CUDA Graph** allows predefining a sequence of kernel calls as a static graph, reducing runtime scheduling overhead; languages like **Triton** enable developers to write high-performance operators using abstractions closer to data flow (block/tile-level)."

#: ../../architecture_trends/convergence.rst:31
msgid "**总结**：GPU的演进就是在其强大的SIMT通用计算基础上，不断“插入”和“暴露”更多的数据流硬件和编程接口。"
msgstr "**Summary**: The evolution of GPUs involves continuously \"inserting\" and \"exposing\" more data flow hardware and programming interfaces on top of their powerful SIMT general-purpose computing foundation."

#: ../../architecture_trends/convergence.rst:33
msgid "**数据流架构正在“通用化”与“生态化”**："
msgstr "**Data Flow Architectures Are Becoming \"Generalized\" and \"Ecosystem-Oriented\"**:"

#: ../../architecture_trends/convergence.rst:35
msgid "**从可编程性看**：SambaNova的RDU虽然是为模型生成专用数据通路，但其PCU、PMU本身是可编程的；Tenstorrent等架构更是直接集成了RISC-V通用核心来处理控制流和复杂逻辑。这解决了早期数据流架构灵活性不足的问题。"
msgstr ""
"**From the Perspective of Programmability**: Although SambaNova's RDU generates dedicated data paths for models, its PCUs and PMUs are inherently programmable; architectures like Tenstorrent even directly integrate RISC-V general-purpose cores to handle control flow and complex logic. This addresses the lack of flexibility in early data flow architectures."

#: ../../architecture_trends/convergence.rst:36
msgid ""
"**从软件生态看**：所有新兴的数据流架构都在积极拥抱 "
"**MLIR** 等主流编译器中间表示，以便能更顺畅地接入PyTorch、TensorFlow等生态系统，降低用户的迁移成本。"
msgstr ""
"**From the Perspective of Software Ecosystems**: All emerging data flow architectures are actively embracing mainstream compiler intermediate representations such as **MLIR**, enabling seamless integration with ecosystems like PyTorch and TensorFlow, and reducing user migration costs."

#: ../../architecture_trends/convergence.rst:39
msgid "主流形态"
msgstr "Mainstream Form"

#: ../../architecture_trends/convergence.rst:41
msgid "主流AI芯片架构都是一种 **“分层协作”** 的工作模式："
msgstr "Mainstream AI chip architectures all adopt a **\"layered collaboration\"** working model:"

#: ../../architecture_trends/convergence.rst:43
msgid "**高层（应用与框架层）**：开发者使用PyTorch等高级框架定义模型。"
msgstr "**Upper Layer (Application and Framework Layer)**: Developers define models using high-level frameworks such as PyTorch."

#: ../../architecture_trends/convergence.rst:44
msgid "**中层（编译器与IR层）**：**MLIR** 等统一中间表示将高层计算图降级，进行与硬件无关的图优化。"
msgstr "**Middle Layer (Compiler and IR Layer)**: Unified intermediate representations like **MLIR** lower high-level computation graphs and perform hardware-agnostic graph optimizations."

#: ../../architecture_trends/convergence.rst:45
msgid "**底层（代码生成与硬件映射层）**：Triton、XLA、Poplar等特定于硬件的编译器后端，将计算图块（subgraph）或算子，智能地映射到底层硬件。"
msgstr "**Lower Layer (Code Generation and Hardware Mapping Layer)**: Hardware-specific compiler backends such as Triton, XLA, and Poplar intelligently map subgraphs or operators to the underlying hardware."

#: ../../architecture_trends/convergence.rst:46
msgid ""
"**硬件层**：一个由 **通用可编程核心** （如RISC-V或GPU SM）作为“调度员”，调度和控制多个 "
"**专用数据流加速器** （如张量核、脉动阵列）协同工作。数据在这些单元之间，通过 "
"**由编译器静态规划好的、硬件支持的显式数据网络** 高效流动。"
msgstr ""
"**Hardware Layer**: A \"dispatcher\" composed of **general-purpose programmable cores** (e.g., RISC-V or GPU SMs) schedules and controls multiple **specialized data flow accelerators** (e.g., tensor cores, systolic arrays) to work collaboratively. Data flows efficiently between these units through **compiler-statically planned, hardware-supported explicit data networks**."

#: ../../architecture_trends/convergence.rst:48
msgid "这种融合架构既能利用数据流硬件实现主流算子（如GEMM）的极致性能，又能通过通用核心保证处理任意计算的灵活性，最终在性能、能效和通用性之间达到最佳平衡。"
msgstr ""
"This converged architecture can leverage data flow hardware to achieve extreme performance for mainstream operators (e.g., GEMM) while ensuring flexibility for handling arbitrary computations through general-purpose cores, ultimately striking an optimal balance between performance, energy efficiency, and versatility."

#: ../../architecture_trends/product_landscape.rst:2
msgid "主流架构分析"
msgstr "Analysis of Mainstream Architectures"

#: ../../architecture_trends/product_landscape.rst:6
msgid ""
"本章节将深入剖析主流AI芯片的技术架构，涵盖 NVIDIA GPU、Google TPU、Graphcore IPU、SambaNova RDU "
"及 Cerebras WSE 等。我们将详细阐述各自的架构特色、技术演进脉络，并重点分析其与数据流思想的异同。"
msgstr ""
"This chapter will conduct an in-depth analysis of the technical architectures of mainstream AI chips, including NVIDIA GPU, Google TPU, Graphcore IPU, SambaNova RDU, and Cerebras WSE. We will elaborate on their respective architectural features, technical evolution trajectories, and focus on analyzing their similarities and differences with data flow concepts."

#: ../../architecture_trends/product_landscape.rst:9
msgid "NVIDIA GPU"
msgstr "NVIDIA GPU"

#: ../../architecture_trends/product_landscape.rst:11
msgid ""
"**核心思想演进**：NVIDIA GPU 的基石是 "
"**SIMT (单指令多线程)** 控制流模型，通过上万线程的并发执行隐藏数据访问延迟。然而，面对AI负载中日益增长的“内存墙”问题，其架构正清晰地向“通用控制流+专用数据流”的混合模式演进。GPU不再仅仅依赖线程并发，而是引入了越来越多数据流风格的专用硬件与显式数据搬运机制。"
msgstr ""
"**Evolution of Core Ideas**: The cornerstone of NVIDIA GPUs is the **SIMT (Single Instruction, Multiple Threads)** control flow model, which hides data access latency through concurrent execution of tens of thousands of threads. However, facing the growing \"memory wall\" problem in AI workloads, their architecture is clearly evolving toward a hybrid model of \"general-purpose control flow + specialized data flow.\" Instead of relying solely on thread concurrency, GPUs are incorporating an increasing number of data flow-style specialized hardware and explicit data transfer mechanisms."

#: ../../architecture_trends/product_landscape.rst:13
msgid "**架构演变脉络**："
msgstr "**Architectural Evolution Trajectory**:"

#: ../../architecture_trends/product_landscape.rst:15
msgid ""
"**Tesla - 控制流范式的奠基**：Tesla架构是NVIDIA发展史的分水岭。它首次引入 "
"**统一渲染架构**，将过去分离的、专用的顶点和像素处理单元，统一为通用的 "
"**CUDA核心**。更重要的是，它确立了 **SIMT (单指令多线程)** 的执行模型。这套组合拳将GPU从一个固定功能的图形管线，彻底转变为一个高度灵活的、由指令驱动的并行 "
"**控制流计算引擎**，为GPGPU时代奠定了基石。"
msgstr ""
"**Tesla - Foundation of the Control Flow Paradigm**: The Tesla architecture was a watershed moment in NVIDIA's development. It introduced the **Unified Shader Architecture** for the first time, unifying previously separate, specialized vertex and pixel processing units into general-purpose **CUDA Cores**. More importantly, it established the **SIMT (Single Instruction, Multiple Threads)** execution model. This combination transformed GPUs from fixed-function graphics pipelines into highly flexible, instruction-driven parallel **control flow computing engines**, laying the foundation for the GPGPU era."

#: ../../architecture_trends/product_landscape.rst:16
msgid ""
"**Fermi - 硬件缓存的引入**：Fermi架构首次为GPU引入了类似CPU的 "
"**L1/L2缓存**。这是典型的控制流解决“内存墙”的思路——通过硬件管理的缓存来隐藏访存延迟。同时，它引入的 "
"**GPUDirect** 技术，首次允许GPU在不经过CPU的情况下直接通信，这是优化系统级 "
"**数据流动** 效率的早期尝试，为后来更高效的多卡互联技术埋下了伏笔。"
msgstr ""
"**Fermi - Introduction of Hardware Caching**: The Fermi architecture introduced CPU-like **L1/L2 caches** to GPUs for the first time. This is a typical control flow approach to addressing the \"memory wall\"—hiding memory access latency through hardware-managed caches. Additionally, it introduced **GPUDirect** technology, which for the first time allowed GPUs to communicate directly without going through the CPU. This was an early attempt to optimize system-level **data flow** efficiency, paving the way for more efficient multi-GPU interconnection technologies later."

#: ../../architecture_trends/product_landscape.rst:17
msgid ""
"**Volta - 专用数据流引擎的引入**：首次引入 "
"**Tensor Core**。这是GPU架构演进的里程碑。Tensor Core 是一个专为矩阵乘加（GEMM：D=A×B+C）设计的 "
"**专用数据流引擎**，它以固定流水线高效处理数据，是数据流思想在GPU内部的首次硬件化实现。"
msgstr ""
"**Volta - Introduction of Specialized Data Flow Engines**: First introduction of **Tensor Cores**. This was a milestone in GPU architectural evolution. Tensor Cores are **specialized data flow engines** designed specifically for matrix multiply-accumulate (GEMM: D=A×B+C) operations. They process data efficiently through fixed pipelines, representing the first hardware implementation of data flow concepts within GPUs."

#: ../../architecture_trends/product_landscape.rst:19
msgid "**Tensor Core工作原理**："
msgstr "**Tensor Core Working Principle**:"

#: ../../architecture_trends/product_landscape.rst:21
msgid ""
"**微型数据流处理器**: Tensor Core 本质上是一个 **高度特化、不可编程的微型数据流处理器**。与执行单一指令的CUDA "
"Core不同，Tensor Core由一条上层指令触发后，会在内部自动执行一个固定的、由硬件定义的矩阵乘加数据流图。"
msgstr ""
"**Micro Dataflow Processor**: Tensor Core is essentially a **highly specialized, non-programmable micro dataflow processor**. Unlike CUDA Cores that execute single instructions, once triggered by a high-level instruction, the Tensor Core automatically executes a fixed, hardware-defined dataflow graph for matrix multiplication and accumulation internally."

#: ../../architecture_trends/product_landscape.rst:22
msgid ""
"**局部数据复用**: "
"输入的矩阵块被加载到其专用的内部寄存器后，数据会在其内部的乘法器和加法器阵列中流动和复用，一次性完成整个块的计算。中间的部分和过程结果始终保持在Core内部，直到最终结果累加完成。这完美体现了数据流架构“最大化片上复用，最小化数据搬运”的核心思想。"
msgstr ""
"**Local Data Reuse**: "
"After input matrix blocks are loaded into its dedicated internal registers, the data flows and is reused within the internal multiplier and adder arrays to complete the computation of the entire block in one go. Intermediate partial and process results remain inside the Core until the final result is accumulated. This perfectly embodies the core idea of dataflow architecture: \"maximize on-chip reuse and minimize data movement.\""

#: ../../architecture_trends/product_landscape.rst:23
msgid ""
"**混合精度计算**: 其广泛采用的 **混合精度计算** "
"模式（例如，FP16输入相乘，FP32累加）是支撑这种高吞吐量数据流设计的关键技术，它在保证数值精度的同时，大幅降低了对内存带宽的需求。"
msgstr ""
"**Mixed-Precision Computing**: The widely adopted **mixed-precision computing** "
"mode (e.g., FP16 input multiplication with FP32 accumulation) is a key technology supporting this high-throughput dataflow design. While ensuring numerical precision, it significantly reduces memory bandwidth requirements."

#: ../../architecture_trends/product_landscape.rst
msgid "NVIDIA Tensor Core 混合精度矩阵乘加示意图"
msgstr "Schematic Diagram of NVIDIA Tensor Core's Mixed-Precision Matrix Multiplication and Accumulation"

#: ../../architecture_trends/product_landscape.rst:29
msgid ""
"上图示意了Tensor "
"Core在执行混合精度矩阵乘加时的典型数据流：低精度输入（如FP16）被加载到本地寄存器和专用乘加阵列中，以高度流水化的方式完成大规模乘法运算，而累加过程则在更高精度（如FP32）的累加寄存器中进行。通过在硬件中固化这种“低精度乘法"
" + 高精度累加”的模式，能显著提升单位带宽的算力。"
msgstr ""
"The figure above illustrates the typical dataflow of the Tensor "
"Core when performing mixed-precision matrix multiplication and accumulation: low-precision inputs (e.g., FP16) are loaded into local registers and dedicated multiply-accumulate arrays to complete large-scale multiplication operations in a highly pipelined manner, while the accumulation process is carried out in higher-precision (e.g., FP32) accumulation registers. By hardwiring this \"low-precision multiplication "
"+ high-precision accumulation\" mode in hardware, the computational power per unit bandwidth is significantly improved."

#: ../../architecture_trends/product_landscape.rst:31
msgid "**引入Tensor Core的意义**:"
msgstr "**Significance of Introducing Tensor Cores**:"

#: ../../architecture_trends/product_landscape.rst:33
msgid ""
"**效率提升**: 其数量级的效率提升，根源于这种数据流设计。它将通用CUDA "
"Core需要执行的数十条独立的加载、乘法、加法、存储指令，聚合为硬件内部的一次自动化数据流动过程，极大地减少了指令调度、寄存器文件访问和数据移动的开销。"
msgstr ""
"**Efficiency Improvement**: Its order-of-magnitude efficiency gain stems from this dataflow design. It aggregates dozens of independent load, multiply, add, and store instructions that general-purpose CUDA "
"Cores would need to execute into a single automated dataflow process within the hardware, greatly reducing the overhead of instruction scheduling, register file access, and data movement."

#: ../../architecture_trends/product_landscape.rst:34
msgid ""
"**架构的决定性转变**: 这一设计标志着GPU从纯粹的通用SIMT（单指令多线程）架构，向 **“通用SIMT + 专用数据流引擎”** "
"的混合架构演进。GPU不再只依赖于“更多、更快的通用核心”，而是通过嵌入专用数据流硬件来加速AI等领域的核心计算负载。"
msgstr ""
"**Decisive Architectural Shift**: This design marks the evolution of GPUs from a purely general-purpose SIMT (Single Instruction, Multiple Threads) architecture to a hybrid architecture of **\"General-Purpose SIMT + Specialized Dataflow Engines\"**. "
"GPUs no longer rely solely on \"more and faster general-purpose cores\" but instead accelerate core computational workloads in fields like AI by embedding specialized dataflow hardware."

#: ../../architecture_trends/product_landscape.rst:36
msgid ""
"**Hopper (数据流思想的深化) - 显式数据移动与领域专用数据流**：Hopper架构将数据流思想的融合推向了新的高度。 1. "
"**Transformer 引擎：软硬协同的专用数据流系统**"
msgstr ""
"**Hopper (Deepening of Dataflow Ideas) - Explicit Data Movement and Domain-Specific Dataflow**: The Hopper architecture takes the integration of dataflow ideas to new heights. 1. "
"**Transformer Engine: A Specialized Dataflow System with Hardware-Software Coordination**"

#: ../../architecture_trends/product_landscape.rst:39
msgid ""
"**硬件层面**：Hopper 在 Tensor Core 及其周边控制逻辑中集成了针对 Transformer 工作负载优化的 "
"**数据流执行路径**，原生支持FP8/BF16等混合精度格式以及缩放因子管理等机制，用以高效完成Attention和MLP等关键算子。"
msgstr ""
"**Hardware Level**: Hopper integrates **dataflow execution paths** optimized for Transformer workloads within its Tensor Cores and surrounding control logic. It natively supports mixed-precision formats such as FP8/BF16 and mechanisms like scaling factor management to efficiently execute key operators such as Attention and MLP."

#: ../../architecture_trends/product_landscape.rst:40
msgid ""
"**软件层面与数据流关系**： **Transformer Engine (TE) 软件库** 则是这套软硬协同方案的 "
"**编程接口与训练优化库**。运行时，它将底层Tensor Core对FP8的支持与上层应用（如PyTorch）连接起来，其数据流体现在："
msgstr ""
"**Software Level and Dataflow Relationship**: The **Transformer Engine (TE) software library** serves as the "
"**programming interface and training optimization library** for this hardware-software co-design solution. At runtime, it bridges the underlying FP8 support of Tensor Cores with upper-layer applications (e.g., PyTorch), and its dataflow is reflected in:"

#: ../../architecture_trends/product_landscape.rst:42
msgid ""
"**显式的数据流区域定义**: 当开发者使用 `with te.fp8_autocast(...)` 这样的API时，他们实际上是在代码中 "
"**显式地声明了一个计算区域**。TE库会捕获这个区域内的所有计算，并将其作为一个整体的 **子图 (Subgraph)**。"
msgstr ""
"**Explicit Dataflow Region Definition**: When developers use APIs like `with te.fp8_autocast(...)`, they are essentially "
"**explicitly declaring a computation region** in the code. The TE library captures all computations within this region and treats it as an integrated **subgraph**."

#: ../../architecture_trends/product_landscape.rst:43
msgid ""
"**自动映射到硬件数据流**：可以直观地理解为把PyTorch 代码翻译成 Hopper 硬件能直接高效执行的形式。TE "
"库会负责把这个子图铺到芯片内部的数据流通路上，同时自动选择合适的 FP8 缩放因子并调用最合适的融合 Kernel，这些底层细节都对开发者透明。"
msgstr ""
"**Automatic Mapping to Hardware Dataflow**: This can be intuitively understood as translating PyTorch code into a form that Hopper hardware can directly and efficiently execute. The TE "
"library handles mapping this subgraph to the internal dataflow paths of the chip, automatically selects appropriate FP8 scaling factors, and invokes the most suitable fused kernels—all low-level details are transparent to developers."

#: ../../architecture_trends/product_landscape.rst:44
msgid ""
"**抽象与自动化**: 这个过程将原本需要开发者手动管理的数十个底层操作（精度转换、数值缩放、矩阵乘、非线性激活等），**抽象并自动化** "
"为一个单一的、高效的硬件执行流程。这正是“图算融合”和数据流思想的精髓——将一个计算图优化并执行在最适合它的专用硬件上，对用户隐藏底层复杂性。"
msgstr ""
"**Abstraction and Automation**: This process **abstracts and automates** "
"dozens of low-level operations that previously required manual management by developers (precision conversion, numerical scaling, matrix multiplication, non-linear activation, etc.) into a single, efficient hardware execution flow. This is the essence of \"graph-computation fusion\" and dataflow ideas—optimizing a computation graph and executing it on the specialized hardware best suited for it, while hiding low-level complexity from users."

#: ../../architecture_trends/product_landscape.rst:46
msgid "下面是一个PyTorch中的代码示例，直观地展示了开发者如何定义一个FP8计算区域："
msgstr "The following is a code example in PyTorch that intuitively shows how developers define an FP8 computation region:"

#: ../../architecture_trends/product_landscape.rst:66
msgid ""
"在这个例子中， ``with te.fp8_autocast(...)`` "
"上下文管理器所包裹的代码块，就是被TE库识别并整体调度到专用硬件数据流引擎上执行的计算子图。"
msgstr ""
"In this example, the code block wrapped by the ``with te.fp8_autocast(...)`` "
"context manager is the computation subgraph that is recognized by the TE library and scheduled as a whole to execute on the specialized hardware dataflow engine."

#: ../../architecture_trends/product_landscape.rst:68
msgid ""
"**Tensor Memory Accelerator (TMA)**：TMA允许在共享内存和全局内存之间进行 "
"**异步、显式的块数据传输**。TMA像一条可编程的数据通路，把这些块沿着预先规划好的路径推送到指定位置。从数据流的角度看，TMA "
"把原来由缓存自动完成的数据转移变成了可见、可调度的 "
"**块级数据流**，计算线程只消费本地缓冲中的数据，数据在片上以流水线方式不断前推，这极大地提升了对片上数据流水的规划能力与效率。"
msgstr ""
"**Tensor Memory Accelerator (TMA)**: TMA enables **asynchronous, explicit block data transfers** between shared memory and global memory. "
"TMA acts as a programmable data path, pushing these blocks to designated locations along pre-planned routes. From a dataflow perspective, TMA "
"transforms data transfers that were previously handled automatically by caches into visible, schedulable "
"**block-level dataflow**. Computation threads only consume data from local buffers, and data is continuously pipelined on-chip, which greatly enhances the ability to plan and efficiency of on-chip data pipelines."

#: ../../architecture_trends/product_landscape.rst:69
msgid ""
"**后续演进 "
"(Blackwell等)**：延续并强化了“通用控制+专用数据流”的混合架构路线。**以Blackwell架构为例，其搭载的第二代Transformer引擎进一步增强了对FP4/FP6等微精度格式的支持，并引入了专门的片上网络交换结构，再次印证了通过专用数据流硬件加速关键工作负载，并赋予软件更大控制权限的演进趋势。**"
msgstr ""
"**Subsequent Evolution (Blackwell, etc.)**: "
"This continues and strengthens the hybrid architectural route of \"general-purpose control + specialized dataflow\". **Taking the Blackwell architecture as an example, its second-generation Transformer Engine further enhances support for micro-precision formats such as FP4/FP6 and introduces a dedicated on-chip network switching fabric. This reaffirms the evolutionary trend of accelerating key workloads through specialized dataflow hardware and granting greater control to software.**"

#: ../../architecture_trends/product_landscape.rst:71
msgid "**与纯数据流架构的同异**："
msgstr "**Similarities and Differences with Pure Dataflow Architectures**:"

#: ../../architecture_trends/product_landscape.rst:73
msgid ""
"**异**：GPU 的根基仍是SIMT控制流，保留了极高的编程灵活性和通用性；而纯数据流架构（如SambaNova "
"RDU）则完全由数据的可用性驱动计算。GPU是“指令驱动+数据流辅助”，后者是“数据完全驱动”。因此，GPU存在“图算分离”问题：计算图的调度依赖CPU和驱动，每个算子（Kernel）作为一个独立的控制流单元被启动，算子间的衔接（数据回写和再读取）会产生大量开销。"
msgstr ""
"**Differences**: The foundation of GPUs remains SIMT control flow, retaining a high degree of programming flexibility and generality; in contrast, pure dataflow architectures (e.g., SambaNova "
"RDU) are completely driven by data availability for computations. GPUs are \"instruction-driven + dataflow-assisted\", while the latter are \"fully data-driven\". Consequently, GPUs face the \"graph-computation separation\" problem: the scheduling of computation graphs relies on the CPU and driver, each operator (kernel) is launched as an independent control flow unit, and the handoff between operators (data write-back and re-read) incurs significant overhead."

#: ../../architecture_trends/product_landscape.rst:74
msgid ""
"**同**：两者都致力于解决“内存墙”问题。GPU通过引入Tensor "
"Core、TMA等来最大化片上计算和数据复用，这与数据流架构的核心目标——“最大化本地性”是完全一致的。"
msgstr ""
"**Similarities**: Both aim to address the \"memory wall\" problem. By introducing Tensor "
"Cores, TMA, and other components to maximize on-chip computation and data reuse, GPUs align perfectly with the core goal of dataflow architecture—\"maximizing locality\"."

#: ../../architecture_trends/product_landscape.rst:76
msgid ""
"**趋势**：GPU沿着“**通用可编程性 + "
"专用数据流加速**”的混合路线演进。一方面，CUDA核心将继续为通用和非主流算子提供灵活性；另一方面，更多针对主流模型（如LLM、MoE）的专用数据流硬件将被集成，同时软件层面（如CUDA"
" Graph, Triton）将提供更多显式控制数据流动的能力，让编译器和开发者能更深地参与到性能优化中。"
msgstr ""
"**Trend**: GPUs are evolving along the hybrid route of \"**General-Purpose Programmability + "
"Specialized Dataflow Acceleration**\". On one hand, CUDA Cores will continue to provide flexibility for general-purpose and non-mainstream operators; on the other hand, more specialized dataflow hardware targeting mainstream models (e.g., LLM, MoE) will be integrated. Meanwhile, software layers (e.g., CUDA "
"Graph, Triton) will offer greater capabilities for explicit control of data flow, enabling compilers and developers to participate more deeply in performance optimization."

#: ../../architecture_trends/product_landscape.rst:79
msgid "Google TPU"
msgstr "Google TPU"

#: ../../architecture_trends/product_landscape.rst:81
msgid ""
"**核心思想**：TPU是一种 **领域专用架构 (DSA)**，其核心是硬件化的数据流计算模式。但它并非理论上的“纯”数据流机器，而是一个由 "
"**指令驱动的、静态调度的混合架构**。"
msgstr ""
"**Core Idea**: TPU is a **Domain-Specific Architecture (DSA)** whose core is a hardware-implemented dataflow computation model. However, it is not a theoretical \"pure\" dataflow machine but rather a "
"**hybrid architecture driven by instructions and statically scheduled**."

#: ../../architecture_trends/product_landscape.rst:83
msgid "**混合架构的本质**："
msgstr "**Essence of the Hybrid Architecture**:"

#: ../../architecture_trends/product_landscape.rst:85
msgid ""
"**数据流核心（MXU）**：其脉动阵列(Systolic "
"Array)设计是数据流思想的极致体现。数据在阵列中规律地流动和计算，实现了极高的数据复用和计算效率。"
msgstr ""
"**Dataflow Core (MXU)**: Its systolic array design is the ultimate embodiment of dataflow ideas. "
"Data flows and is computed regularly within the array, achieving extremely high data reuse and computational efficiency."

#: ../../architecture_trends/product_landscape.rst:86
msgid "**控制流驱动**：然而，整个TPU的运作是由宿主CPU（Host）启动，并由其片上控制器执行一个预先编译好的、VLIW风格的指令序列来精确协调其内部的各个单元。因此，是“指令”在宏观上调度“数据流”，而非数据自发驱动计算。"
msgstr "**Control Flow Driven**: However, the entire operation of the TPU is initiated by the host CPU and precisely coordinated across its internal components by its on-chip controller executing a precompiled, VLIW-style instruction sequence. Therefore, it is \"instructions\" that schedule \"dataflow\" at the macro level, rather than data driving computations autonomously."

#: ../../architecture_trends/product_landscape.rst:-1
msgid "Google TPU 脉动阵列（Systolic Array）矩阵乘加数据流示意"
msgstr "Schematic Diagram of Matrix Multiplication and Accumulation Dataflow in Google TPU's Systolic Array"

#: ../../architecture_trends/product_landscape.rst:92
msgid "上图展示了TPU中典型的脉动阵列结构：输入矩阵A和B的元素分别沿着阵列的行与列方向在MAC单元阵列中“脉动”传输，每个乘加单元在接收到来自上游和左侧的数据后立即执行乘加运算，并将部分和沿着阵列方向继续传递。通过这种方式，同一行/列的数据会在阵列内部被多次复用，大量乘加操作得以高度流水化地并行展开，极大减少了对片外内存的访问需求，充分体现了数据流架构中“让数据在阵列中流动、让计算紧随数据而动”的设计思想。"
msgstr "The figure above illustrates the typical systolic array structure in the TPU: elements of input matrices A and B are \"systolically\" transmitted along the row and column directions of the MAC (Multiply-Accumulate) unit array, respectively. Each MAC unit immediately performs multiply-accumulate operations upon receiving data from the upstream and left sides, and passes the partial sum along the array direction. In this way, data from the same row/column is reused multiple times within the array, enabling a large number of multiply-accumulate operations to be executed in highly pipelined parallelism. This significantly reduces the need for off-chip memory access and fully embodies the design philosophy of dataflow architecture: \"let data flow within the array and computations follow the data.\""

#: ../../architecture_trends/product_landscape.rst:94
msgid "**架构演进与关键模块**："
msgstr "**Architectural Evolution and Key Modules**:"

#: ../../architecture_trends/product_landscape.rst:96
msgid ""
"**TPUv1 (奠基)**：作为推理加速器，确立了 **MXU + 片上统一缓冲 (Unified Buffer)** "
"的基本模式，采用INT8精度，由CPU通过PCIe接口下发指令。"
msgstr ""
"**TPUv1 (Foundation Laying)**: As an inference accelerator, it established the basic model of **MXU (Matrix Multiply Unit) + On-Chip Unified Buffer**, "
"adopted INT8 precision, and received instructions from the CPU via the PCIe interface."

#: ../../architecture_trends/product_landscape.rst:97
msgid ""
"**TPUv2/v3 (迈向训练与系统级数据流)**：这是决定性的一步。引入了 **HBM高带宽内存** 和 **BF16/FP32** "
"浮点计算能力以支持模型训练。最关键的创新是引入了 **ICI (Inter-Chip Interconnect)** "
"高速片间互联网络。ICI将数十上百个TPU芯片连接成一个 **TPU Pod**，形成一个巨大的、分布式的 "
"**系统级数据流机器**。数据可以在不同芯片的计算核心间高效流动，摆脱了单芯片的限制。"
msgstr ""
"**TPUv2/v3 (Towards Training and System-Level Dataflow)**: This was a decisive step. It introduced **HBM (High-Bandwidth Memory)** and **BF16/FP32** "
"floating-point computing capabilities to support model training. The most critical innovation was the introduction of the **ICI (Inter-Chip Interconnect)** "
"high-speed inter-chip network. The ICI connects dozens to hundreds of TPU chips into a **TPU Pod**, forming a massive, distributed "
"**system-level dataflow machine**. Data can flow efficiently between computing cores of different chips, breaking free from the limitations of a single chip."

#: ../../architecture_trends/product_landscape.rst:98
msgid ""
"**TPUv4及后续 "
"(性能与灵活性的深化)**：持续提升MXU算力、内存带宽和ICI网络速度。**TPUv4i和最新的TPUv5p等型号，不仅在峰值性能上大幅超越前代，也持续优化ICI网络拓扑与带宽，并增强了周边向量与标量单元的可编程性**，以处理日益复杂的非矩阵运算。这标志着TPU从一个相对固化的ASIC，演变为一个算力强大且灵活性不断增强的"
" **可扩展计算集群**。"
msgstr ""
"**TPUv4 and Beyond (Deepening of Performance and Flexibility)**: "
"Continuous improvements have been made to MXU computing power, memory bandwidth, and ICI network speed. **Models such as TPUv4i and the latest TPUv5p not only significantly surpass their predecessors in peak performance but also continuously optimize ICI network topology and bandwidth, while enhancing the programmability of peripheral vector and scalar units** to handle increasingly complex non-matrix operations. This marks the evolution of the TPU from a relatively fixed ASIC to a powerful and increasingly flexible "
"**scalable computing cluster**."

#: ../../architecture_trends/product_landscape.rst:100
msgid ""
"**编译器(XLA + MLIR)**：TPU的强大高度依赖 **XLA (Accelerated Linear Algebra)** "
"编译器。XLA将高层计算图（如TensorFlow/PyTorch图）完整地编译成底层的、静态的指令序列，精确规划好每一个周期的数据流向和计算任务，实现了极致的"
" "
"**“图算一体”**，最大化硬件效率。**值得注意的是，XLA正越来越多地采用MLIR作为其中间表示（IR），利用MLIR的方言（Dialect）机制来更好地表示和优化高层计算图，然后再降级到TPU专属的底层表示。**"
msgstr ""
"**Compiler (XLA + MLIR)**: The power of the TPU is highly dependent on the **XLA (Accelerated Linear Algebra)** "
"compiler. XLA fully compiles high-level computation graphs (e.g., TensorFlow/PyTorch graphs) into low-level, static instruction sequences, precisely planning the data flow and computation tasks for each cycle to achieve the ultimate "
"**\"graph-computation integration\"** and maximize hardware efficiency. **Notably, XLA is increasingly adopting MLIR as its intermediate representation (IR), leveraging MLIR's dialect mechanism to better represent and optimize high-level computation graphs before lowering them to TPU-specific low-level representations.**"

#: ../../architecture_trends/product_landscape.rst:102
msgid ""
"**趋势总结**：TPU的演进路线，是从一个单芯片的、以数据流为核心的推理引擎，发展成为一个由控制流指令静态调度的、通过高速网络将众多数据流核心连接起来的"
" **大规模、可编程、系统级的数据流计算平台**。"
msgstr ""
"**Trend Summary**: The evolutionary path of the TPU has been from a single-chip, dataflow-centric inference engine to a "
"**large-scale, programmable, system-level dataflow computing platform** that is statically scheduled by control flow instructions and connects numerous dataflow cores through high-speed networks."

#: ../../architecture_trends/product_landscape.rst:105
msgid "IPU (Graphcore)"
msgstr "IPU (Graphcore)"

#: ../../architecture_trends/product_landscape.rst:107
msgid ""
"**核心思想**：**MIMD (多指令多数据流) + 分布式片上内存**。IPU "
"将芯片划分为上千个独立的处理器核心（Tile），每个Tile拥有自己的本地SRAM和计算单元，并能执行独立的指令流。它彻底抛弃了GPU的硬件缓存一致性，强调"
" **数据的显式放置和通信**。"
msgstr ""
"**Core Idea**: **MIMD (Multiple Instruction, Multiple Data) + Distributed On-Chip Memory**. The IPU "
"divides the chip into thousands of independent processor cores (Tiles), each with its own local SRAM and computation unit, capable of executing independent instruction streams. It completely abandons the hardware cache coherence of GPUs and emphasizes "
"**explicit data placement and communication**."

#: ../../architecture_trends/product_landscape.rst:109
#: ../../architecture_trends/product_landscape.rst:137
#: ../../architecture_trends/product_landscape.rst:179
msgid "**架构要点**："
msgstr "**Key Architectural Features**:"

#: ../../architecture_trends/product_landscape.rst:111
msgid "**大规模Tile**：上千个核心，每个都能独立工作，非常适合处理具有不规则并行性的任务（如图神经网络、稀疏计算）。"
msgstr "**Large-Scale Tiles**: Thousands of cores, each capable of working independently, making it ideal for handling tasks with irregular parallelism (e.g., graph neural networks, sparse computing)."

#: ../../architecture_trends/product_landscape.rst:112
msgid "**完全分布式的SRAM**：数据被编译器显式地划分并放置到每个Tile的本地内存中，计算也只在本地内存上进行。这最大化了数据局部性，实现了超高片上带宽和极低功耗。"
msgstr "**Fully Distributed SRAM**: Data is explicitly partitioned by the compiler and placed in the local memory of each Tile, with computations performed exclusively on local memory. This maximizes data locality, achieving ultra-high on-chip bandwidth and extremely low power consumption."

#: ../../architecture_trends/product_landscape.rst:113
msgid ""
"**显式通信**：当核心间需要数据交换时，必须通过 **BSP (块同步并行)** "
"模型由编译器在软件（Poplar）中进行显式、可预测的数据同步与搬移。这避免了硬件缓存一致性的开销和不确定性。"
msgstr ""
"**Explicit Communication**: When data exchange between cores is required, it must be performed through the **BSP (Bulk Synchronous Parallel)** "
"model, with explicit, predictable data synchronization and movement implemented by the compiler in software (Poplar). This avoids the overhead and uncertainty of hardware cache coherence."

#: ../../architecture_trends/product_landscape.rst:115
msgid "从程序执行的角度看，BSP在IPU上的作用可以理解为 **计算-通信-同步** 三个阶段："
msgstr "From the perspective of program execution, the role of BSP on the IPU can be understood as three phases: **Compute-Communicate-Synchronize**:"

#: ../../architecture_trends/product_landscape.rst:117
msgid ""
"**本地计算 "
"(Compute)**：在一个阶段内部，每个Tile只访问自己的本地SRAM，执行分配给自己的指令流和数据片段。由于不需要访问共享缓存或远端内存，这一阶段可以以极高带宽、极低延迟运行，是IPU能效优势的来源之一。"
msgstr ""
"**Local Computation (Compute)**: "
"Within a phase, each Tile only accesses its own local SRAM and executes the assigned instruction stream and data segments. Since there is no need to access shared caches or remote memory, this phase can run with ultra-high bandwidth and extremely low latency, making it one of the sources of the IPU's energy efficiency advantage."

#: ../../architecture_trends/product_landscape.rst:118
msgid ""
"**数据交换 "
"(Exchange)**：当本地计算阶段结束，某些Tile需要其它Tile的中间结果时，程序进入显式通信阶段。Poplar会根据预先编译好的计划，通过片上网络在指定Tile之间搬运数据，数据路径和数据量在编译期就已确定。"
msgstr ""
"**Data Exchange (Exchange)**: "
"When the local computation phase ends and certain Tiles require intermediate results from other Tiles, the program enters the explicit communication phase. Based on a precompiled plan, Poplar moves data between designated Tiles via the on-chip network, with data paths and data volumes determined at compile time."

#: ../../architecture_trends/product_landscape.rst:119
msgid ""
"**全局同步 "
"(Barrier)**：所有数据交换完成后，进入同步点。只有当所有Tile都到达这一屏障时，下一轮本地计算才会开始。这使整个系统的执行顺序在时间上高度可预测，便于性能分析和调优。"
msgstr ""
"**Global Synchronization (Barrier)**: "
"After all data exchanges are completed, a synchronization point is reached. The next round of local computation begins only when all Tiles have arrived at this barrier. This makes the execution sequence of the entire system highly predictable in time, facilitating performance analysis and optimization."

#: ../../architecture_trends/product_landscape.rst:121
msgid "对开发者而言，这种BSP模型带来了两点直接收益：一是编程负担降低——不需要像在GPU上那样管理成千上万线程的细粒度同步，而是以“轮”为单位思考算法结构；二是跨芯片扩展更加自然——当多个IPU通过高速互联组成大集群时，同样可以按BSP节拍在不同芯片之间进行批量数据交换，把“单芯片多Tile”的编程模型平滑地扩展到“多芯片多Tile”的系统级数据流执行。"
msgstr "For developers, this BSP model offers two direct benefits: first, reduced programming burden—instead of managing fine-grained synchronization for thousands of threads as on GPUs, algorithms are designed in terms of \"supersteps\"; second, more natural cross-chip scaling—when multiple IPUs are connected into a large cluster via high-speed interconnects, bulk data exchange between different chips can be performed in BSP cycles, smoothly extending the \"single-chip multi-Tile\" programming model to \"multi-chip multi-Tile\" system-level dataflow execution."

#: ../../architecture_trends/product_landscape.rst:122
msgid "**MIMD**：与GPU的SIMD不同，MIMD允许每个核心执行不同的程序，处理复杂的分支和不规则任务时效率更高。"
msgstr "**MIMD**: Unlike the SIMD of GPUs, MIMD allows each core to execute different programs, resulting in higher efficiency when handling complex branches and irregular tasks."

#: ../../architecture_trends/product_landscape.rst:-1
msgid "Graphcore IPU Tile 网格与显式数据放置示意"
msgstr "Schematic Diagram of Graphcore IPU Tile Grid and Explicit Data Placement"

#: ../../architecture_trends/product_landscape.rst:128
msgid ""
"上图以网格化的方式展示了Graphcore "
"IPU内部由大量Tile构成的计算与存储结构：每个小方块代表一个带本地SRAM的Tile，它们通过片上网络彼此相连。编译器会把计算图拆分成许多小片段，并将每个片段及其数据显式地“放置”到某些Tile上；当需要跨Tile通信时，则通过BSP模型在特定的同步点统一交换数据。与依赖硬件缓存透明搬运数据的GPU不同，这种显式划分与通信让开发者和编译器能够像规划一张数据流图那样，精确控制数据在芯片上的分布和流动路径。"
msgstr ""
"The figure above illustrates the computation and storage structure of the Graphcore "
"IPU, composed of a large number of Tiles arranged in a grid: each small square represents a Tile with local SRAM, interconnected via an on-chip network. The compiler splits the computation graph into many small segments and explicitly \"places\" each segment and its associated data onto specific Tiles; when cross-Tile communication is required, data is exchanged uniformly at specific synchronization points via the BSP model. Unlike GPUs that rely on hardware caches for transparent data movement, this explicit partitioning and communication enable developers and compilers to precisely control the distribution and flow paths of data on the chip, much like planning a dataflow graph."

#: ../../architecture_trends/product_landscape.rst:130
msgid "**数据流特征**：IPU的数据放置和通信具有强烈的数据流特征。开发者不再依赖硬件缓存，而是像规划数据流图一样，思考数据如何在众核间分布和流动。"
msgstr "**Dataflow Characteristics**: The data placement and communication of the IPU exhibit strong dataflow features. Developers no longer rely on hardware caches but instead plan how data is distributed and flows across many cores, similar to designing a dataflow graph."

#: ../../architecture_trends/product_landscape.rst:133
msgid "SambaNova (RDU)"
msgstr "SambaNova (RDU)"

#: ../../architecture_trends/product_landscape.rst:135
msgid ""
"**核心思想**： **可重构数据流架构 "
"(RDU)**。SambaNova是纯粹数据流路线的典型代表，其核心理念是通过编译器将AI模型的高层计算图 **直接映射** "
"为芯片底层的硬件数据通路配置，为每个模型“生成”一个专用的ASIC。"
msgstr ""
"**Core Idea**: **Reconfigurable Dataflow Architecture (RDU)**. "
"SambaNova is a typical representative of the pure dataflow approach. Its core philosophy is to **directly map** the high-level computation graph of an AI model to the underlying hardware data path configuration of the chip through a compiler, \"generating\" a dedicated ASIC for each model."

#: ../../architecture_trends/product_landscape.rst:139
msgid "**可重构数据流单元 (RDU)**：由大量模式计算单元（PCU）、模式存储单元（PMU）和交换网络组成。"
msgstr "**Reconfigurable Dataflow Unit (RDU)**: Composed of a large number of Pattern Compute Units (PCUs), Pattern Memory Units (PMUs), and an interconnection network."

#: ../../architecture_trends/product_landscape.rst:140
msgid "**编译器定义硬件**：编译器分析计算图后，会决定如何将算子映射到PCU，数据存放于哪个PMU，以及它们之间如何通过片上网络连接。硬件配置是动态的、模型专用的。"
msgstr "**Compiler-Defined Hardware**: After analyzing the computation graph, the compiler determines how to map operators to PCUs, which PMUs store data, and how they connect via the on-chip network. The hardware configuration is dynamic and model-specific."

#: ../../architecture_trends/product_landscape.rst:141
msgid "**图算融合**：实现了极致的“图算融合”，消除了GPU“图算分离”带来的Kernel启动和数据回写开销。"
msgstr "**Graph-Computation Fusion**: Achieves extreme \"graph-computation fusion\", eliminating the kernel launch and data write-back overhead caused by the \"graph-computation separation\" in GPUs."

#: ../../architecture_trends/product_landscape.rst:142
msgid ""
"**三层内存系统 (SN40L)**：为了解决大模型时代的“内存墙”，SN40L采用了 **片上SRAM + HBM + DDR** "
"的三层内存架构，并由软件系统智能管理，实现了高带宽和大容量的兼得，尤其适合专家混合（CoE）等模型。"
msgstr ""
"**Three-Tier Memory System (SN40L)**: To address the \"memory wall\" in the era of large models, the SN40L adopts a three-tier memory architecture of **On-Chip SRAM + HBM + DDR**, "
"intelligently managed by the software system. It achieves both high bandwidth and large capacity, making it particularly suitable for models such as Mixture of Experts (MoE/CoE)."

#: ../../architecture_trends/product_landscape.rst:-1
msgid "SambaNova RDU 可重构数据流架构示意"
msgstr "Schematic Diagram of SambaNova RDU's Reconfigurable Dataflow Architecture"

#: ../../architecture_trends/product_landscape.rst:148
msgid ""
"上图示意了SambaNova "
"RDU的整体数据流架构：上层编译器首先对AI模型的计算图进行分析和划分，然后将算子映射到片上的模式计算单元（PCU），将中间数据与权重放置在模式存储单元（PMU）中，并通过可重构的交换网络在PCU/PMU之间建立专用的数据通路。对每一个模型而言，RDU内部的连接关系和数据流路径都可以被重新配置，相当于为该模型“定制”了一块专用加速芯片，从而在保持通用编程接口的同时获得接近专用ASIC的效率。"
msgstr ""
"The figure above illustrates the overall dataflow architecture of the SambaNova "
"RDU: the upper-layer compiler first analyzes and partitions the computation graph of the AI model, then maps operators to on-chip Pattern Compute Units (PCUs), places intermediate data and weights in Pattern Memory Units (PMUs), and establishes dedicated data paths between PCUs/PMUs via a reconfigurable interconnection network. For each model, the internal connections and dataflow paths of the RDU can be reconfigured, equivalent to \"customizing\" a dedicated acceleration chip for the model. This achieves efficiency close to that of a dedicated ASIC while maintaining a general-purpose programming interface."

#: ../../architecture_trends/product_landscape.rst:150
msgid "从工程实现角度看，RDU 的“可重构”并不是硬件层面的变化，而是通过可编程的片上交换网络和配置寄存器，在较粗粒度上重组算子单元与存储单元："
msgstr "From an engineering implementation perspective, the \"reconfigurability\" of the RDU does not involve changes at the hardware level, but rather the coarse-grained reorganization of operator units and storage units through programmable on-chip interconnection networks and configuration registers:"

#: ../../architecture_trends/product_landscape.rst:152
msgid ""
"在网络层面，PCU/PMU "
"的输入输出全部挂在一张可编程交换网络上，编译器生成的配置比特决定了“谁和谁相连、数据沿哪条路径流动”，从而为不同模型“重新布线”，把逻辑上的计算图固化为物理上的数据流路径。"
msgstr ""
"At the network level, the input and output of all PCUs/PMUs "
"are connected to a single programmable interconnection network. Configuration bits generated by the compiler determine \"who is connected to whom and which path data flows along\", thereby \"rewiring\" for different models and solidifying the logical computation graph into a physical dataflow path."

#: ../../architecture_trends/product_landscape.rst:153
msgid ""
"在单元层面，PCU "
"内部实现了一套支持矩阵乘、卷积、向量运算等模式的专用运算结构，不同模型通过写入不同的配置寄存器或微指令序列，就能把同一块硬件单元用作不同算子的流水线，而PMU则可在权重缓冲、激活缓存、流控FIFO等角色之间切换。"
msgstr ""
"At the unit level, each PCU "
"internally implements a set of dedicated arithmetic structures supporting modes such as matrix multiplication, convolution, and vector operations. By writing different configuration registers or microinstruction sequences, different models can use the same hardware unit as a pipeline for different operators, while PMUs can switch between roles such as weight buffers, activation caches, and flow-control FIFOs."

#: ../../architecture_trends/product_landscape.rst:155
msgid ""
"因此，虽然硅片上的 "
"PCU/PMU/片上网络结构本身是固定的，但它们的“角色分工”和“连接方式”可以随着模型重新分配，使得同一块RDU在不同时刻表现为针对不同网络结构优化的“专用加速器”，这就是其“可重构数据流架构”的真正含义。"
msgstr ""
"Therefore, although the physical structure of PCUs/PMUs/on-chip networks on the silicon wafer is fixed, their \"role division\" and \"connection methods\" can be reallocated according to the model. "
"This allows the same RDU to function as a \"dedicated accelerator\" optimized for different network structures at different times, which is the true meaning of its \"reconfigurable dataflow architecture\"."

#: ../../architecture_trends/product_landscape.rst:158
msgid "Tenstorrent"
msgstr "Tenstorrent"

#: ../../architecture_trends/product_landscape.rst:160
msgid ""
"**核心思想**：**通用可编程核 + 专用张量单元 + 片上/片间数据流网络**。Tenstorrent 的芯片（如 "
"Grayskull、Wormhole）并不只是一个“算力黑盒”，而是由大量具备路由能力的计算核心组成，每个核心既能作为通用处理器执行复杂控制流，又能驱动本地张量单元完成高吞吐的矩阵计算，并通过高速NoC和以太网在芯片内外路由数据流。"
msgstr ""
"**Core Idea**: **General-Purpose Programmable Cores + Specialized Tensor Units + On-Chip/Inter-Chip Dataflow Network**. Tenstorrent's chips (e.g., "
"Grayskull, Wormhole) are not just \"computational black boxes\" but consist of a large number of routing-capable compute cores. Each core can act as a general-purpose processor to execute complex control flows, drive local tensor units for high-throughput matrix computations, and route data flows inside and outside the chip via high-speed NoC (Network-on-Chip) and Ethernet."

#: ../../architecture_trends/product_landscape.rst:162
msgid "**架构要点（以 Wormhole 为例）**："
msgstr "**Key Architectural Features (Taking Wormhole as an Example)**:"

#: ../../architecture_trends/product_landscape.rst:164
msgid ""
"**Worker Core = 张量单元 + RISC-V/ARC 核心**：每个计算核心内部包含专用的张量计算单元和多核RISC-V/ARC "
"CPU。典型用法是：将标准张量算子（如GEMM、卷积）下放到张量单元，而将不规则控制流、稀疏操作、通信协议栈等逻辑交给通用CPU执行。"
msgstr ""
"**Worker Core = Tensor Unit + RISC-V/ARC Cores**: Each compute core internally integrates dedicated tensor computation units and multi-core RISC-V/ARC "
"CPUs. A typical usage is to offload standard tensor operators (e.g., GEMM, convolution) to the tensor units, while delegating logic such as irregular control flows, sparse operations, and communication protocol stacks to the general-purpose CPUs."

#: ../../architecture_trends/product_landscape.rst:165
msgid ""
"**高带宽外设与存储**：Wormhole 芯片集成了 **16 路 100G 以太网、6 通道 GDDR6、PCIe Gen4 "
"x16**，既能作为独立加速卡挂在主机上，又能通过以太网直接组网，构建大规模、去中心化的AI计算集群。"
msgstr ""
"**High-Bandwidth Peripherals and Storage**: The Wormhole chip integrates **16 ports of 100G Ethernet, 6-channel GDDR6, and PCIe Gen4 "
"x16**. It can be used as an independent acceleration card attached to a host or directly networked via Ethernet to build large-scale, decentralized AI computing clusters."

#: ../../architecture_trends/product_landscape.rst:166
msgid "**片上网络即路由结构**：芯片内部的核心通过NoC连接，每个核心都具备路由能力，可以将其他核心甚至其他芯片的流量“转发”到目的地。整个系统可以被视为一个由计算+路由节点构成的分布式数据流图。"
msgstr "**NoC as Routing Infrastructure**: Cores inside the chip are connected via a NoC, and each core has routing capabilities to \"forward\" traffic from other cores or even other chips to the destination. The entire system can be viewed as a distributed dataflow graph composed of compute + routing nodes."

#: ../../architecture_trends/product_landscape.rst:-1
msgid "Tenstorrent Wormhole 芯片平面与接口示意"
msgstr "Schematic Diagram of Tenstorrent Wormhole Chip Layout and Interfaces"

#: ../../architecture_trends/product_landscape.rst:172
msgid ""
"上图展示了Wormhole芯片的平面结构：中间的大规模计算核心阵列周围环绕着GDDR6内存控制器、PCIe和多路100G以太网接口。每个 `T` "
"形标记代表一个具备张量计算和路由能力的核心，芯片边缘的以太网接口使得多个芯片可以像交换机一样直接互联，构成一个既负责计算又负责数据转发的“AI路由网络”。这种设计与传统“单卡算力堆叠”的GPU路线不同，更强调在系统层面通过数据流图和路由策略来组织大规模分布式训练与推理。"
msgstr ""
"The figure above shows the layout of the Wormhole chip: a large-scale compute core array in the middle is surrounded by GDDR6 memory controllers, PCIe, and multiple 100G Ethernet interfaces. Each `T`-shaped "
"marker represents a core with tensor computation and routing capabilities. The Ethernet interfaces on the chip edge allow multiple chips to be directly interconnected like switches, forming an \"AI routing network\" that handles both computation and data forwarding. Unlike the traditional GPU route of \"single-card compute stacking\", this design emphasizes organizing large-scale distributed training and inference at the system level through dataflow graphs and routing strategies."

#: ../../architecture_trends/product_landscape.rst:175
msgid "Cerebras (WSE)"
msgstr "Cerebras (WSE)"

#: ../../architecture_trends/product_landscape.rst:177
msgid ""
"**核心思想**： **晶圆级引擎 (Wafer-Scale Engine, "
"WSE)和数据流架构**。Cerebras通过将一整块晶圆打造成一颗芯片（**最新已达WSE-3**），实现了前所未有的计算核心数量（**WSE-3已达90万核**）和片上网络带宽，其执行模型是纯粹的数据流。"
msgstr ""
"**Core Idea**: **Wafer-Scale Engine (WSE)** "
"**and Dataflow Architecture**. Cerebras transforms an entire silicon wafer into a single chip (**the latest generation is WSE-3**), achieving an unprecedented number of compute cores (**up to 900,000 cores in WSE-3**) and on-chip network bandwidth. Its execution model is pure dataflow."

#: ../../architecture_trends/product_landscape.rst:181
msgid "**海量核心与本地内存**：数十万个可编程核心，每个核心都有自己的本地SRAM，指令和数据都存储在本地。"
msgstr "**Massive Cores and Local Memory**: Hundreds of thousands of programmable cores, each with its own local SRAM for storing instructions and data."

#: ../../architecture_trends/product_landscape.rst:182
msgid "**数据触发执行**：计算完全由数据的到达来触发。片上网络（Fabric）直接在硬件中传输数据，数据一旦到达核心，立即触发相应的计算。"
msgstr "**Data-Triggered Execution**: Computations are completely triggered by the arrival of data. The on-chip network (Fabric) transmits data directly in hardware, and computations are initiated immediately upon data reaching the core."

#: ../../architecture_trends/product_landscape.rst:183
msgid "**稀疏计算亲和性**：网络硬件可以在发送端过滤掉零值数据，因此计算核心只处理非零数据，天然地实现了稀疏计算加速。"
msgstr "**Sparse Computation Affinity**: The network hardware can filter out zero-value data at the sender, so compute cores only process non-zero data, natively achieving sparse computation acceleration."

#: ../../architecture_trends/product_landscape.rst:184
msgid "**内存设计**：将内存完全分布在计算单元旁边，使得内存带宽与核心的数据通路带宽相匹配，从物理上解决了内存瓶颈。"
msgstr "**Memory Design**: Memory is fully distributed alongside compute units, matching memory bandwidth with the data path bandwidth of the cores and physically resolving the memory bottleneck."

#: ../../architecture_trends/product_landscape.rst:186
msgid "**晶圆级方案的优势与意义**："
msgstr "**Advantages and Significance of the Wafer-Scale Solution**:"

#: ../../architecture_trends/product_landscape.rst:188
msgid "**超大单芯片算力，减少“多卡拼接”的复杂度**：传统路线需要依赖几十上百块GPU/TPU再通过NVLink、以太网等互联来拼出足够的算力和存储，跨芯片的同步和通信往往成为性能瓶颈。WSE则在一块物理连续的晶圆上集成了海量核心和片上存储，将资源浓缩成一个单设备节点，使得大模型可以尽量在单芯片内部完成训练/推理，显著降低了分布式并行的切分和协调复杂度。"
msgstr "**Ultra-Large Single-Chip Computing Power, Reducing the Complexity of \"Multi-Card Stitching\"**: Traditional routes rely on dozens to hundreds of GPUs/TPUs interconnected via NVLink, Ethernet, etc., to achieve sufficient computing power and storage, where cross-chip synchronization and communication often become performance bottlenecks. In contrast, the WSE integrates massive cores and on-chip storage on a single physically contiguous wafer, concentrating resources into a single device node. This allows large models to complete training/inference as much as possible within a single chip, significantly reducing the partitioning and coordination complexity of distributed parallelism."

#: ../../architecture_trends/product_landscape.rst:189
msgid ""
"**极致的片上带宽与数据本地性**：WSE采用“核心+本地SRAM+片上网络”的模式，大部分中间激活、权重切片和KV-"
"Cache都可以在晶圆内部高复用，数据在邻近核心之间以短距离流动，极少出片访问外部DRAM。这不仅规避了“内存墙”的带宽与能耗瓶颈，也减少了因等待远程数据而产生的计算空转，从而在大模型工作负载下获得更高的有效利用率和能效。"
msgstr ""
"**Extreme On-Chip Bandwidth and Data Locality**: The WSE adopts a \"core + local SRAM + on-chip network\" model. Most intermediate activations, weight slices, and KV-Cache "
"can be highly reused within the wafer. Data flows over short distances between adjacent cores, with minimal off-chip access to external DRAM. This not only avoids the bandwidth and energy consumption bottlenecks of the \"memory wall\" but also reduces compute idleness caused by waiting for remote data, thereby achieving higher effective utilization and energy efficiency under large-model workloads."

#: ../../architecture_trends/product_landscape.rst:190
msgid "**对数据流/图执行天然友好**：WSE内部呈现出一块规则的大规模核心网格，与数据流编译器的视角高度契合。编译器可以将计算图节点均匀铺展到核心阵列上，将依赖边映射为核心之间的点对点数据通路，在编译期完成大部分调度与路由规划。相较于拓扑层次复杂的多芯片系统，这种“晶圆级大网格”更容易实现图算一体的全局优化，使得Cerebras在超大规模AI模型上能够以更简单的软件抽象换取更高的系统整体效率。"
msgstr "**Naturally Friendly to Dataflow/Graph Execution**: The WSE internally features a regular large-scale core grid, which aligns highly with the perspective of dataflow compilers. The compiler can evenly distribute computation graph nodes across the core array, map dependency edges to point-to-point data paths between cores, and complete most scheduling and routing planning at compile time. Compared to multi-chip systems with complex topological hierarchies, this \"wafer-scale large grid\" is more conducive to achieving global optimization of integrated graph and computation, enabling Cerebras to exchange simpler software abstractions for higher overall system efficiency in ultra-large-scale AI models."

#: ../../architecture_trends/significance.rst:2
msgid "众核数据流架构"
msgstr "Many-Core Dataflow Architecture"

#: ../../architecture_trends/significance.rst:5
msgid "在深入探讨众核数据流架构之前，我们先回顾一下当前占据统治地位的两种计算架构——CPU与GPU，这将有助于我们理解数据流架构诞生的背景与独特价值。"
msgstr "Before delving into the many-core dataflow architecture, we first review the two dominant computing architectures today—CPU and GPU. This will help us understand the background and unique value of the emergence of dataflow architecture."

#: ../../architecture_trends/significance.rst:7
msgid ""
"**CPU (Central Processing Unit)**：作为通用计算的基石，CPU 遵循经典的 "
"**冯·诺依曼架构**。其核心设计目标是处理极其复杂的控制逻辑（分支预测、乱序执行等）。"
msgstr ""
"**CPU (Central Processing Unit)**: As the cornerstone of general-purpose computing, the CPU adheres to the classic "
"**von Neumann architecture**. Its core design goal is to handle extremely complex control logic (branch prediction, out-of-order execution, etc.)."

#: ../../architecture_trends/significance.rst:9
msgid ""
"**复杂的内存设计与控制单元**：CPU "
"的晶体管预算大量投入到了巨大的缓存（Cache）和复杂的控制单元上。它的设计目标是尽快完成一个串行任务。因此，它拥有强大的分支预测能力来减少跳转等待，以及乱序执行来填补流水线空闲。"
msgstr ""
"**Complex Memory Design and Control Unit**: A large portion of the CPU's transistor budget is invested in massive caches "
"and complex control units. Its design goal is to complete a serial task as quickly as possible. Therefore, it possesses strong branch prediction capabilities to reduce jump waiting and out-of-order execution to fill pipeline gaps."

#: ../../architecture_trends/significance.rst:10
msgid "**计算单元占比低**：相比于控制逻辑和缓存，真正的算术逻辑单元（ALU）在 CPU 芯片面积中的占比其实很小。"
msgstr "**Low Proportion of Compute Units**: Compared to control logic and caches, the actual proportion of Arithmetic Logic Units (ALUs) in the CPU chip area is relatively small."

#: ../../architecture_trends/significance.rst:11
msgid ""
"**共享内存与缓存一致性**：为了简化多核编程，CPU 在硬件层面实现了复杂的 **缓存一致性协议 (如 "
"MESI)**。这意味着所有核心看到的内存视图必须时刻保持一致。这种“强中心化”的设计虽然方便了软件开发，但在核心数量增加时，维护一致性的广播与同步开销会急剧上升，限制了大规模并行扩展能力。"
msgstr ""
"**Shared Memory and Cache Coherence**: To simplify multi-core programming, CPUs implement complex **cache coherence protocols (e.g., "
"MESI)** at the hardware level. This means the memory view seen by all cores must remain consistent at all times. While this \"strongly centralized\" design facilitates software development, as the number of cores increases, the overhead of broadcasting and synchronization to maintain coherence rises sharply, limiting large-scale parallel scalability."

#: ../../architecture_trends/significance.rst:12
msgid ""
"**控制流模式**：程序计数器（PC）指引 CPU 逐条读取指令，指令再指挥数据进行移动和计算。这种模式虽然赋予了 CPU "
"处理复杂计算任务的强大能力，但在面对海量重复的计算任务时，其复杂的控制逻辑反而成为了负担。"
msgstr ""
"**Control Flow Model**: The Program Counter (PC) guides the CPU to fetch instructions one by one, and the instructions then direct data movement and computation. While this model endows the CPU with "
"strong capabilities to handle complex computing tasks, its complex control logic becomes a burden when facing massive repetitive computing tasks."

#: ../../architecture_trends/significance.rst:14
msgid "**GPU (Graphics Processing Unit)**：为了解决图形渲染中大规模并行计算的需求，GPU 应运而生。"
msgstr "**GPU (Graphics Processing Unit)**: The GPU emerged to address the demand for large-scale parallel computing in graphics rendering."

#: ../../architecture_trends/significance.rst:16
msgid "**大规模计算核心**：GPU 将晶体管预算主要投入到了海量的计算核心（ALU）上，以此换取极致的并行吞吐量。它大大简化了控制逻辑和缓存层级。"
msgstr "**Large-Scale Compute Cores**: GPUs allocate most of their transistor budget to a massive number of compute cores (ALUs) in exchange for extreme parallel throughput. They significantly simplify control logic and cache hierarchies."

#: ../../architecture_trends/significance.rst:17
msgid ""
"**SIMT (单指令多线程)**：GPU 采用 SIMT "
"模型，一个指令流同时控制成千上万个线程。这种方式非常适合处理图形像素或矩阵运算这种整齐规律的任务。同时，GPU "
"靠切换线程来降低延迟。当一组线程在等待内存数据时，GPU 会迅速切换到另一组就绪的线程继续计算，从而保持流水线繁忙。"
msgstr ""
"**SIMT (Single Instruction, Multiple Threads)**: GPUs adopt the SIMT "
"model, where a single instruction stream controls tens of thousands of threads simultaneously. This approach is well-suited for regular, uniform tasks such as graphics pixel processing or matrix operations. Additionally, "
"GPUs reduce latency through thread switching. When one group of threads is waiting for memory data, the GPU quickly switches to another ready group to continue computing, keeping the pipeline busy."

#: ../../architecture_trends/significance.rst:18
msgid ""
"**中心化的控制模式**：虽然 GPU 拥有海量核心，但它们通常通过共享的 L2 缓存或全局显存（Global "
"Memory）交换数据。更重要的是，GPU 的执行高度依赖 Host CPU "
"的指令调度。这种中心化的存储与控制模式，在面对极大规模分布式计算时，依然存在同步与通信的瓶颈。"
msgstr ""
"**Centralized Control Model**: Despite having a massive number of cores, GPUs typically exchange data through shared L2 caches or Global "
"Memory. More importantly, GPU execution is highly dependent on instruction scheduling from the Host CPU. "
"This centralized storage and control model still faces synchronization and communication bottlenecks when dealing with extremely large-scale distributed computing."

#: ../../architecture_trends/significance.rst:19
msgid ""
"**局限性**：尽管并行度极高，GPU 本质上仍未脱离 **“指令驱动”** "
"的范式。数据必须等待指令下达后才能被处理，且数据在内存层级间的移动仍受指令控制。Host CPU 仍需不断通过总线向 GPU "
"发送指令，这引入了额外的开销。"
msgstr ""
"**Limitations**: Despite its high parallelism, the GPU essentially remains within the **\"instruction-driven\"** "
"paradigm. Data can only be processed after instructions are issued, and data movement between memory hierarchies is still controlled by instructions. The Host CPU must continuously send instructions to the GPU "
"via the bus, introducing additional overhead."

#: ../../architecture_trends/significance.rst:21
msgid ""
"然而，随着 AI "
"模型参数量与计算量的指数级增长，这种“指令控制数据”的模式日益显现出瓶颈：指令解码的开销、线程同步的等待、以及最致命的“内存墙”问题。"
msgstr ""
"However, with the exponential growth in the number of parameters and computational demands of AI "
"models, this \"instruction-controlled data\" model has increasingly revealed bottlenecks: instruction decoding overhead, thread synchronization waiting, and the most critical \"memory wall\" problem."

#: ../../architecture_trends/significance.rst:23
msgid ""
"正是在这种背景下，**数据流架构 (Dataflow Architecture)** "
"作为一种“回归计算本质”的范式成为了新的选择。它不再由指令流控制执行顺序，而是 "
"**由数据的可用性直接驱动计算**。这种范式与传统冯·诺依曼架构截然不同，为解决大规模 AI 计算难题提供了全新的思路。"
msgstr ""
"Against this backdrop, **Dataflow Architecture** "
"has emerged as a new choice as a paradigm that \"returns to the essence of computing\". It no longer controls the execution order through instruction streams but instead "
"**directly drives computation through data availability**. This paradigm is fundamentally different from the traditional von Neumann architecture, offering a new approach to solving large-scale AI computing challenges."

#: ../../architecture_trends/significance.rst:26
msgid "数据驱动的执行模式"
msgstr "Data-Driven Execution Model"

#: ../../architecture_trends/significance.rst:28
msgid "计算操作（如数据流图中的节点）的执行，不是由传统的程序计数器（PC）按顺序取指令决定，而是由其所有依赖的输入数据是否准备好来决定。这与GPU的“控制流”模式截然不同。GPU依赖于CPU发来的指令流，按顺序启动一个个计算核（Kernel），即使数据早已在显存中准备就绪，也必须等待指令到达才能执行。数据流架构则消除了这种“指令等待数据”的延迟，计算单元在数据到达的那一刻就可以立即开始工作，实现了真正的“数据驱动计算”。"
msgstr "The execution of computational operations (such as nodes in a dataflow graph) is not determined by the traditional Program Counter (PC) fetching instructions sequentially, but by whether all dependent input data is ready. This is fundamentally different from the GPU's \"control flow\" model. GPUs rely on instruction streams from the CPU to launch kernels one by one in sequence—even if data is already ready in video memory, execution must wait for instructions to arrive. In contrast, the dataflow architecture eliminates this \"instruction waiting for data\" latency; compute units can start working immediately upon data arrival, achieving true \"data-driven computing\"."

#: ../../architecture_trends/significance.rst:31
msgid "图算结合"
msgstr "Integration of Graph and Computation"

#: ../../architecture_trends/significance.rst:33
msgid ""
"数据流架构具有良好的图适应性，程序被编译成一个数据流图（Dataflow Graph），节点是算子（Operator），边代表数据依赖和流动方向。"
" "
"这是数据流架构的灵魂所在，编译器精确地知道A计算单元何时完成计算，以及B计算单元何时需要这个结果。因此，它可以生成指令，让数据在精确的时间点，通过NoC从A直接发送到B。"
" "
"也就是说我们可以通过在软件编译层面的设计，来减少硬件通信方面的开销。相较于GPU的图算分离，数据流架构与传统的图计算框架（如TensorFlow、PyTorch）具备较好的相性。"
msgstr ""
"The dataflow architecture exhibits excellent graph adaptability: programs are compiled into a Dataflow Graph, where nodes represent operators and edges represent data dependencies and flow directions. "
"This is the soul of the dataflow architecture—the compiler precisely knows when compute unit A will complete its computation and when compute unit B will need this result. Therefore, it can generate instructions to send data directly from A to B via the NoC at an exact time point. "
"In other words, we can reduce hardware communication overhead through design at the software compilation level. Compared to the separation of graph and computation in GPUs, the dataflow architecture is highly compatible with traditional graph computing frameworks (such as TensorFlow and PyTorch)."

#: ../../architecture_trends/significance.rst:-1
msgid "数据流图中算子节点与数据依赖边的示意"
msgstr "Schematic Diagram of Operator Nodes and Data Dependency Edges in a Dataflow Graph"

#: ../../architecture_trends/significance.rst:41
msgid "上图以图形化方式展示了一个典型的数据流图：每个圆圈或方块代表一个算子节点，连线则表示前后算子之间的数据依赖和张量流向。编译器正是基于这样的图结构来规划哪些算子可以并行执行、哪些中间结果可以直接在片上转发，从而在硬件层面构建出与计算图高度一致的数据流执行路径。"
msgstr "The figure above graphically illustrates a typical dataflow graph: each circle or square represents an operator node, and the connecting lines indicate data dependencies and tensor flow directions between successive operators. Based on this graph structure, the compiler plans which operators can be executed in parallel and which intermediate results can be directly forwarded on-chip, thereby constructing a dataflow execution path at the hardware level that is highly consistent with the computation graph."

#: ../../architecture_trends/significance.rst:44
msgid "编程范式对比实例：Kernel 模式 vs 图模式"
msgstr "Programming Paradigm Comparison Example: Kernel Model vs. Graph Model"

#: ../../architecture_trends/significance.rst:46
msgid ""
"为了更直观地理解这两种架构的差异，我们可以通过一个简单的“向量加法后乘法”（ :math:`D = (B + C) \\times E` "
"）的计算任务，来对比它们在编程模型上的根本不同。"
msgstr ""
"To more intuitively understand the differences between these two architectures, we can compare their fundamental differences in programming models through a simple computational task of \"vector addition followed by multiplication\" ( :math:`D = (B + C) \\times E` "
")."

#: ../../architecture_trends/significance.rst:48
msgid "**1. GPU 的编程模型：以 Kernel 为中心的指令驱动**"
msgstr "**1. GPU Programming Model: Kernel-Centered Instruction-Driven**"

#: ../../architecture_trends/significance.rst:50
msgid ""
"在 GPU 开发（如 CUDA）中，开发者往往需要将计算任务拆解为一个个独立的 **Kernel（内核）**。每个 Kernel "
"完成一个简单的步骤，中间结果必须写回全局显存（Global Memory），下一个 Kernel 再从显存中读取。Host CPU "
"像一个指挥官，不断下达指令启动 Kernel。"
msgstr ""
"In GPU development (e.g., CUDA), developers often need to decompose computational tasks into independent **Kernels**. Each Kernel "
"completes a simple step, and intermediate results must be written back to Global Memory before the next Kernel reads them. The Host CPU "
"acts as a commander, continuously issuing instructions to launch Kernels."

#: ../../architecture_trends/significance.rst:52
msgid "GPU 编程模式"
msgstr "GPU Programming Model"

#: ../../architecture_trends/significance.rst:92
msgid ""
"**问题所在**：即使 `add_kernel` 和 `mul_kernel` 只是简单的操作，中间数据 `A` 也必须经历“写回显存 -> "
"读取显存”的过程。对于 GPU 而言，两个 Kernel 之间是隔离的，必须通过中心化的显存来传递状态，且需要 Host CPU "
"的介入来协调顺序。"
msgstr ""
"**Problem**: Even if `add_kernel` and `mul_kernel` are simple operations, the intermediate data `A` must undergo the process of \"write back to video memory -> "
"read from video memory\". For GPUs, the two Kernels are isolated; state must be transferred through centralized video memory, and the Host CPU "
"must intervene to coordinate the order."

#: ../../architecture_trends/significance.rst:94
msgid "**2. 数据流架构的编程模型：以图为中心的流式计算**"
msgstr "**2. Dataflow Architecture Programming Model: Graph-Centered Stream Computing**"

#: ../../architecture_trends/significance.rst:96
msgid ""
"在数据流架构中，开发者关注的是 "
"**定义计算图**。算子被映射到芯片上不同的计算单元，数据像流水线一样在单元之间直接流动，**中间结果不写回外部内存**。"
msgstr ""
"In the dataflow architecture, developers focus on "
"**defining the computation graph**. Operators are mapped to different compute units on the chip, data flows directly between units like an assembly line, and **intermediate results are not written back to external memory**."

#: ../../architecture_trends/significance.rst:98
msgid "数据流编程模式"
msgstr "Dataflow Programming Model"

#: ../../architecture_trends/significance.rst:122
msgid ""
"**优势**：这种模式下，`Op.add` 和 `Op.mul` "
"在空间上是并行的（Pipelined）。数据一生产出来就立即被消费，彻底消除了通过中心化显存交换数据的开销，也摆脱了 Host CPU "
"的频繁指令控制。"
msgstr ""
"**Advantages**: In this model, `Op.add` and `Op.mul` "
"are spatially parallel (pipelined). Data is consumed immediately after being produced, completely eliminating the overhead of data exchange through centralized video memory and freeing from the frequent instruction control of the Host CPU."

#: ../../architecture_trends/significance.rst:125
msgid "GPU的困境：内存墙"
msgstr "GPU's Dilemma: The Memory Wall"

#: ../../architecture_trends/significance.rst:127
msgid ""
"而GPU的工作流程往往分为两个部分，CPU先构建并优化图，然后进行图的执行，它按照图中的依赖关系，依次遍历图的节点（算子）。 "
"每当遇到一个算子，CPU就会向GPU下达一个指令：“启动执行器（CUDA Kernel），在XX内存地址上执行XX任务”。 "
"GPU接到指令后，就调度其内部成千上万的计算核心（CUDA "
"Cores）去执行这个Kernel。一个Kernel执行完毕后，通常会将结果写回到GPU的全局显存中。为此，GPU在数据传输上有大量开销，并且内存操作的速度远慢于计算操作的速度，这导致了GPU的计算能力无法得到充分利用，也就是常说的“内存墙问题”。"
" "
"GPU缓解“内存墙”问题的思路通常是疯狂提升带宽，每一代GPU都在追求更高的内存带宽（HBM），从几百GB/s到如今的几个TB/s，但仍然面临着下面的问题："
msgstr ""
"The GPU workflow typically consists of two phases: the CPU first constructs and optimizes the graph, then executes it by traversing the graph's nodes (operators) sequentially according to dependencies. "
"Whenever an operator is encountered, the CPU sends an instruction to the GPU: \"Launch the executor (CUDA Kernel) to perform XX task at XX memory address\". "
"Upon receiving the instruction, the GPU schedules its internal tens of thousands of compute cores (CUDA "
"Cores) to execute the Kernel. After a Kernel completes execution, the results are usually written back to the GPU's global memory. Consequently, GPUs incur significant overhead in data transfer, and memory operations are far slower than compute operations—this prevents the GPU's computing power from being fully utilized, a phenomenon commonly known as the \"memory wall problem\". "
"GPUs typically address the memory wall by aggressively increasing bandwidth; each generation pursues higher memory bandwidth (HBM), evolving from hundreds of GB/s to several TB/s today. However, they still face the following issues:"

#: ../../architecture_trends/significance.rst:132
msgid "算力增长远快于带宽增长：芯片上晶体管密度（以及由此带来的算力FLOPS）的增长速度，远远超过了芯片I/O接口（以及由此带来的带宽）的增长速度。"
msgstr "Computing Power Grows Faster Than Bandwidth: The growth rate of on-chip transistor density (and the resulting computing power in FLOPS) far outpaces the growth rate of chip I/O interfaces (and the resulting bandwidth)."

#: ../../architecture_trends/significance.rst:133
msgid "片外数据搬运存在大量能耗与延迟：将一个数据从DRAM搬到计算单元再写回去的能量开销，可能是执行一次计算本身的上百倍！即使拥有无限的带宽，可以让数据瞬间到达，每一次的访问也都在产生巨大的、不可避免的能量开销。对于需要海量数据吞吐的AI模型来说，这会导致芯片的功耗高得无法接受。"
msgstr "Off-Chip Data Movement Incurs Significant Energy Consumption and Latency: The energy cost of moving a single piece of data from DRAM to a compute unit and writing it back can be hundreds of times higher than the energy cost of the computation itself! Even with unlimited bandwidth that allows instantaneous data arrival, each access generates enormous, unavoidable energy overhead. For AI models requiring massive data throughput, this leads to unacceptably high chip power consumption."

#: ../../architecture_trends/significance.rst:134
msgid ""
"带宽再高也存在传递的延迟：GPU的“图算分离”模式，每次调用一个Kernel，都需要一次完整的“CPU -> GPU驱动 -> Kernel启动 "
"-> 访问DRAM -> "
"写回DRAM”的流程。这个流程本身就存在固有的延迟。虽然GPU通过海量线程（Warp调度）的方式可以隐藏一部分延迟（当一部分线程在等数据时，另一部分线程可以先计算），但延迟本身并没有消失。"
msgstr ""
"Latency Persists Despite High Bandwidth: Due to the GPU's \"separation of graph and computation\" model, each Kernel launch requires a complete workflow: \"CPU -> GPU Driver -> Kernel Launch "
"-> DRAM Access -> "
"DRAM Write-Back\". This workflow inherently introduces latency. While GPUs can hide some latency through massive thread scheduling (Warp scheduling)—allowing other threads to compute while one group waits for data—the latency itself does not disappear."

#: ../../architecture_trends/significance.rst:136
msgid "因此GPU的解决方法是一种“治标不治本”的策略，它能缓解问题，但无法从根本上解决问题。"
msgstr "Thus, the GPU's solution is a \"symptomatic rather than root-cause\" strategy; it mitigates the problem but fails to resolve it fundamentally."

#: ../../architecture_trends/significance.rst:139
msgid "数据流的“治本”之道"
msgstr "Dataflow's \"Root-Cause\" Solution"

#: ../../architecture_trends/significance.rst:141
msgid "而数据流架构，则是一种试图“治本”的全新思路。它不是去缓解内存墙，而是通过减少访存来试图绕开内存墙。"
msgstr "In contrast, the dataflow architecture represents an entirely new approach that aims to address the root cause. Instead of mitigating the memory wall, it attempts to bypass it by reducing memory accesses."

#: ../../architecture_trends/significance.rst:143
msgid "最大化的片上复用：通过编译器的全局规划，让数据尽可能地“定居”在芯片内部的SRAM中，被反复利用。这可以将访存的能耗降低百倍。"
msgstr "Maximized On-Chip Reuse: Through global compiler planning, data is kept in the chip's internal SRAM as much as possible for repeated reuse. This can reduce the energy consumption of memory accesses by hundreds of times."

#: ../../architecture_trends/significance.rst:144
msgid "显式通信：让数据在片上计算单元之间直接“串门”（通过NoC），而不是每次都要先回显存报个到。这极大地降低了中间结果的读写延迟和能耗。"
msgstr "Explicit Communication: Data directly \"moves\" between on-chip compute units (via NoC) instead of being written back to video memory every time. This significantly reduces the read/write latency and energy consumption of intermediate results."

#: ../../architecture_trends/significance.rst:147
msgid "天然的并行性"
msgstr "Natural Parallelism"

#: ../../architecture_trends/significance.rst:149
msgid "由于执行仅依赖于数据，因此在数据流图中，任何两个没有直接数据依赖关系的节点，都可以在硬件资源允许的情况下同时执行。编译器可以轻易地从图中识别出所有潜在的并行机会，无论是算子内部的并行（如向量化），还是算子之间的并行（任务并行），都无需像GPU那样依赖复杂的运行时调度器去动态发掘。整个程序的并行性在编译阶段就可以被静态地、确定性地固定下来。"
msgstr "Since execution depends solely on data availability, any two nodes in a dataflow graph with no direct data dependencies can be executed simultaneously if hardware resources permit. The compiler can easily identify all potential parallelism opportunities from the graph—whether intra-operator parallelism (e.g., vectorization) or inter-operator parallelism (task parallelism)—without relying on complex runtime schedulers to dynamically discover them like GPUs do. The parallelism of the entire program can be statically and deterministically fixed during the compilation phase."

#: ../../architecture_trends/significance.rst:152
msgid "良好的可拓展性"
msgstr "Excellent Scalability"

#: ../../architecture_trends/significance.rst:155
msgid "数据流架构的计算和通信模式是局部化的。每个计算单元主要与其邻近的单元通信。这种特性使得架构可以通过增加更多的计算单元来线性地扩展整个系统的计算能力，而无需担心像传统多核CPU/GPU那样，因共享内存和缓存一致性协议带来的全局通信瓶颈。只要编译器能够将一个更大的计算图映射到更多的硬件单元上，性能就能随之增长，这也是为什么Cerebras能够制造出晶圆级芯片的底层逻辑。"
msgstr "The computation and communication patterns of the dataflow architecture are localized—each compute unit primarily communicates with its neighboring units. This feature allows the architecture to linearly scale the system's computing power by adding more compute units, without the risk of global communication bottlenecks caused by shared memory and cache coherence protocols, as seen in traditional multi-core CPUs/GPUs. As long as the compiler can map a larger computation graph to more hardware units, performance will increase accordingly. This is the underlying logic that enables Cerebras to manufacture wafer-scale chips."

#: ../../architecture_trends/significance.rst:158
msgid "众核数据流架构的局限性"
msgstr "Limitations of Many-Core Dataflow Architecture"

#: ../../architecture_trends/significance.rst:160
msgid "尽管数据流架构在AI计算领域展现出巨大的潜力，但其独特的特性也带来了一系列挑战，这也是其尚未取代传统GPU的原因。"
msgstr "Despite its enormous potential in the field of AI computing, the dataflow architecture's unique characteristics pose a series of challenges, which is why it has not yet replaced traditional GPUs."

#: ../../architecture_trends/significance.rst:162
msgid ""
"**编译器负担的上升** "
"数据流架构将复杂的运行时调度转移到了编译期。这虽然简化了硬件，却极大地增加了编译器的负担。编译器不仅需要理解计算图的结构，还需要精确掌握底层硬件的拓扑、SRAM容量以及通信延迟，以求解一个极度复杂的优化问题。当模型结构变得动态（如MoE路由）时，静态编译很难生成最优的执行计划，导致运行时效率大幅下降。"
msgstr ""
"**Increased Compiler Burden** "
"The dataflow architecture shifts complex runtime scheduling to the compilation phase. While this simplifies hardware, it significantly increases the compiler's burden. The compiler must not only understand the structure of the computation graph but also accurately grasp the underlying hardware topology, SRAM capacity, and communication latency to solve an extremely complex optimization problem. When the model structure becomes dynamic (e.g., MoE routing), static compilation struggles to generate optimal execution plans, leading to a significant drop in runtime efficiency."

#: ../../architecture_trends/significance.rst:165
msgid ""
"**通用性不足与缺乏良好的生态** GPU之所以成功，很大程度上归功于CUDA生态的通用性。数据流架构通常需要专用的软件栈（如Graphcore "
"Poplar, SambaNova "
"SambaFlow），这些软件栈虽然在特定AI负载上表现优异，但缺乏对通用计算（如复杂的控制流、非张量运算）的广泛支持。这使得迁移现有的、依赖大量自定义算子的业务代码变得异常困难。"
msgstr ""
"**Lack of Versatility and Mature Ecosystem** The GPU's success is largely attributed to the versatility of the CUDA ecosystem. Dataflow architectures typically require specialized software stacks (e.g., Graphcore "
"Poplar, SambaNova "
"SambaFlow), which, while excellent for specific AI workloads, lack broad support for general-purpose computing (e.g., complex control flows, non-tensor operations). This makes migrating existing business code that relies heavily on custom operators extremely challenging."

#: ../../architecture_trends/significance.rst:168
msgid ""
"**片上内存容量的限制与高张量并行的副作用** "
"为了追求极致带宽，数据流架构往往依赖昂贵的片上SRAM。然而，SRAM的容量远低于DRAM。面对参数量动辄数千亿的LLM，单核内存远远无法容纳模型权重，导致了下面的结果。"
msgstr ""
"**Limitations of On-Chip Memory Capacity and Side Effects of High Tensor Parallelism** "
"In pursuit of extreme bandwidth, dataflow architectures often rely on expensive on-chip SRAM. However, SRAM capacity is far lower than that of DRAM. Faced with LLMs with hundreds of billions of parameters, single-core memory is completely inadequate to store model weights, leading to the following consequences:"

#: ../../architecture_trends/significance.rst:171
msgid ""
"**高张量并行（Tensor "
"Parallelism）**：为了存下巨大模型，必须将权重矩阵切分到成千上万个核心上。这意味着每一次矩阵乘法运算，都被拆解成了数千个微小的计算任务。"
msgstr ""
"**High Tensor Parallelism**: "
"To store massive models, weight matrices must be partitioned across tens of thousands of cores. This means every matrix multiplication operation is split into thousands of tiny computational tasks."

#: ../../architecture_trends/significance.rst:172
msgid "**核间同步开销激增**：在Transformer架构中，每一层的计算结束都需要来汇总这些计算任务的和。当参与同步的核心数量激增到众核架构的数千个时，片上网络面临巨大的通信压力，通信延迟呈指数级上升。虽然计算被高度并行化了，但通信成为了新的串行瓶颈。大量的计算核心不得不频繁停下来等待邻居的数据，导致算力利用率大幅下降。"
msgstr "**Surge in Inter-Core Synchronization Overhead**: In Transformer architectures, the results of these computational tasks must be aggregated at the end of each layer. When the number of cores participating in synchronization surges to thousands in many-core architectures, the on-chip network faces enormous communication pressure, and communication latency increases exponentially. While computation is highly parallelized, communication becomes a new serial bottleneck. A large number of compute cores have to frequently pause to wait for data from neighboring cores, leading to a significant drop in computing power utilization."

#: ../../architecture_trends/significance.rst:175
msgid "技术实现"
msgstr "Technical Implementation"

#: ../../architecture_trends/significance.rst:176
msgid "为了实现上述理想的设计理念，数据流面对着如下的问题："
msgstr "To realize the above ideal design concepts, dataflow architectures face the following challenges:"

#: ../../architecture_trends/significance.rst:179
msgid "编译器的优化能力"
msgstr "Compiler Optimization Capabilities"

#: ../../architecture_trends/significance.rst:180
msgid "数据流架构将大量的并行性与数据搬移控制交给软件，这要求编译器承担极具挑战性的工作：将高层计算图进行切分、将算子与数据合理映射到众多的处理单元上、规划通信路径与调度执行顺序。这比传统GPU的编译优化更为复杂。"
msgstr "Dataflow architectures delegate extensive parallelism and data movement control to software, requiring compilers to undertake highly challenging tasks: partitioning high-level computation graphs, reasonably mapping operators and data to numerous processing units, and planning communication paths and execution schedules. This is far more complex than the compilation optimization of traditional GPUs."

#: ../../architecture_trends/significance.rst:183
#: ../../architecture_trends/significance.rst:192
#: ../../architecture_trends/significance.rst:201
#: ../../architecture_trends/significance.rst:210
#: ../../architecture_trends/significance.rst:218
msgid "解决方案示例"
msgstr "Example Solutions"

#: ../../architecture_trends/significance.rst:184
msgid "**SambaNova** 的可重构数据流单元（RDU）依赖其独家开发的编译器栈，为每个AI模型自动探索并生成最优的硬件配置与数据流图映射方案。"
msgstr "**SambaNova**'s Reconfigurable Dataflow Unit (RDU) relies on its proprietary compiler stack to automatically explore and generate optimal hardware configurations and dataflow graph mapping schemes for each AI model."

#: ../../architecture_trends/significance.rst:185
msgid ""
"**Graphcore** "
"的Poplar软件栈则要求编译器显式地将计算图划分到上千个处理器核（Tile）上，并管理每个核本地内存（SRAM）中的数据。"
msgstr ""
"**Graphcore**'s "
"Poplar software stack requires the compiler to explicitly partition the computation graph across thousands of processor cores (Tiles) and manage data in each core's local memory (SRAM)."

#: ../../architecture_trends/significance.rst:188
msgid "片上网络（NoC）的设计"
msgstr "Network-on-Chip (NoC) Design"

#: ../../architecture_trends/significance.rst:189
msgid "数据在处理单元之间的大量流动是数据流架构的常态。因此，片上网络必须提供极高的带宽与极低的延迟，以避免其成为性能瓶颈。网络拓扑、路由算法与流控机制的设计至关重要。"
msgstr "Massive data flow between processing units is the norm in dataflow architectures. Therefore, the NoC must provide extremely high bandwidth and extremely low latency to avoid becoming a performance bottleneck. The design of network topology, routing algorithms, and flow control mechanisms is crucial."

#: ../../architecture_trends/significance.rst:193
msgid "**Cerebras** 将整个晶圆刻蚀成一颗芯片，其核心是连接了数十万个处理核心的2D网格网络，提供了惊人的片上带宽，数据抵达后直接触发计算。"
msgstr "**Cerebras** etches an entire wafer into a single chip, with a 2D grid network connecting hundreds of thousands of processing cores at its core. This provides extraordinary on-chip bandwidth, and computations are triggered directly upon data arrival."

#: ../../architecture_trends/significance.rst:194
msgid "**Tenstorrent** 的 Wormhole 芯片设计了高性能的NoC，通过多个64位处理器核心进行路由，从而在多个芯片之间实现低延迟扩展。"
msgstr "**Tenstorrent**'s Wormhole chip features a high-performance NoC that routes data through multiple 64-bit processor cores, enabling low-latency scaling across multiple chips."

#: ../../architecture_trends/significance.rst:197
msgid "对特定计算图的适应性"
msgstr "Adaptability to Specific Computation Graphs"

#: ../../architecture_trends/significance.rst:198
msgid "静态的数据流硬件可能对某种特定结构（如规则的卷积网络）优化到极致，但在处理结构不规则、动态性强（如稀疏网络、Transformer）的模型时效率下降。"
msgstr "Static dataflow hardware may be optimized to the extreme for specific structures (e.g., regular convolutional networks), but its efficiency decreases when processing models with irregular structures and high dynamism (e.g., sparse networks, Transformers)."

#: ../../architecture_trends/significance.rst:202
msgid "**SambaNova RDU** 的“可重构”特性，使其能根据不同模型的计算图，动态调整芯片内部的数据通路，为每个模型定制专用的数据流路径。"
msgstr "The \"reconfigurable\" feature of **SambaNova RDU** enables it to dynamically adjust internal chip data paths according to the computation graphs of different models, customizing dedicated dataflow routes for each model."

#: ../../architecture_trends/significance.rst:203
msgid ""
"**Graphcore IPU** "
"采用MIMD（多指令多数据流）架构，每个核心都能执行不同的程序，相比GPU的SIMT架构，能更灵活地处理分支、稀疏计算等不规则任务。"
msgstr ""
"**Graphcore IPU** adopts the MIMD (Multiple Instruction, Multiple Data) architecture, "
"where each core can execute different programs. Compared to the GPU's SIMT architecture, it can more flexibly handle irregular tasks such as branching and sparse computing."

#: ../../architecture_trends/significance.rst:206
msgid "缓存一致性"
msgstr "Cache Coherence"

#: ../../architecture_trends/significance.rst:207
msgid "传统多核CPU/GPU依赖复杂的硬件缓存一致性协议来维护统一的内存视图，但这在扩展到数千核心时会带来巨大的开销与瓶颈。数据流架构通常会选择绕开这个问题。"
msgstr "Traditional multi-core CPUs/GPUs rely on complex hardware cache coherence protocols to maintain a unified memory view, but this incurs significant overhead and bottlenecks when scaling to thousands of cores. Dataflow architectures typically choose to bypass this problem."

#: ../../architecture_trends/significance.rst:211
msgid ""
"**Graphcore IPU** "
"舍弃了硬件缓存一致性，每个核心只访问自己的本地SRAM。需要跨核通信时，由编译器在Poplar软件中进行显式的、可预测的数据同步与搬移，从而提升了能效与确定性。"
msgstr ""
"**Graphcore IPU** abandons hardware cache coherence; "
"each core only accesses its own local SRAM. When inter-core communication is required, the compiler performs explicit, predictable data synchronization and movement in the Poplar software, thereby improving energy efficiency and determinism."

#: ../../architecture_trends/significance.rst:214
msgid "保证可预测性与同步"
msgstr "Ensuring Predictability and Synchronization"

#: ../../architecture_trends/significance.rst:215
msgid "数据流架构的一个核心优势是通过编译期规划，将复杂的运行时调度与依赖判断转移至编译期完成，从而获得高度确定的性能。"
msgstr "A core advantage of the dataflow architecture is that through compile-time planning, complex runtime scheduling and dependency judgment are transferred to the compilation phase, achieving highly deterministic performance."

#: ../../architecture_trends/significance.rst:219
msgid ""
"**Graphcore IPU** 采用块同步并行（Bulk Synchronous Parallel, "
"BSP）模型，将程序执行划分为“本地计算”和“全局同步”两个阶段，使得并行执行的逻辑大大简化，性能可预测。"
msgstr ""
"**Graphcore IPU** adopts the Bulk Synchronous Parallel (BSP) model, "
"dividing program execution into two phases: \"local computation\" and \"global synchronization\". This greatly simplifies the logic of parallel execution and ensures predictable performance."

#: ../../architecture_trends/significance.rst:220
msgid ""
"**Google TPU** 也应用了数据流架构的思想，通过脉动阵列（Systolic "
"Array）让数据在计算单元之间规律地流动和计算，执行效率极高且时序固定。"
msgstr ""
"**Google TPU** also applies dataflow architecture ideas, using a Systolic "
"Array to enable regular data flow and computation between processing units, achieving extremely high execution efficiency and fixed timing."

#: ../../architecture_trends/significance.rst:224
msgid "时代适应性"
msgstr "Era Adaptability"

#: ../../architecture_trends/significance.rst:227
msgid "工作负载变化"
msgstr "Workload Changes"

#: ../../architecture_trends/significance.rst:228
msgid ""
"**大语言模型（LLM）带来了参数量与序列长度的双重挑战**：LLM的推理过程是内存带宽密集型的。一方面，自回归生成涉及大量KV矩阵"
"，**数据流架构利用片上大容量SRAM实现权重与KV-"
"Cache的本地复用**，避免了反复搬运。另一方面，由于众核架构单核资源有限，大模型部署往往需要极高的张量并行度（Tensor "
"Parallelism），导致核间同步开销激增。对此，数据流架构通过高带宽片上网络（NoC）支持**激活值与中间结果的高效流动**，缓解了由大规模切分带来的通信瓶颈。"
msgstr ""
"**Large Language Models (LLMs) Bring Dual Challenges of Parameter Scale and Sequence Length**: LLM inference is memory bandwidth-intensive. On one hand, autoregressive generation involves a large number of KV matrices; "
"**dataflow architectures use on-chip large-capacity SRAM to achieve local reuse of weights and KV-Cache**, "
"avoiding repeated data movement. On the other hand, due to the limited per-core resources of many-core architectures, large-model deployment often requires extremely high Tensor Parallelism, leading to a surge in inter-core synchronization overhead. In response, dataflow architectures support **efficient flow of activations and intermediate results** through high-bandwidth Network-on-Chip (NoC), alleviating communication bottlenecks caused by large-scale partitioning."

#: ../../architecture_trends/significance.rst:229
msgid ""
"**混合专家模型（MoE）带来了稀疏矩阵处理的问题**：MoE模型在每次前向传播时，仅激活一小部分“专家”网络，这是一种典型的动态稀疏计算。传统GPU的SIMT架构难以处理这种不规则的计算负载，容易导致大量核心空闲（GPU的A100引进了Sparse"
" Tensorcore来缓解这个问题）。而数据流架构，特别是MIMD类型（如Graphcore "
"IPU），可以灵活地将不同任务调度到不同核心，数据流驱动的执行方式天然契合稀疏计算，只在数据到达时才触发计算，能效更高。"
msgstr ""
"**Mixture of Experts (MoE) Models Bring Sparse Matrix Processing Challenges**: During each forward propagation, MoE models only activate a small subset of \"expert\" networks, representing a typical form of dynamic sparse computing. Traditional GPU SIMT architectures struggle to handle such irregular computational workloads, often resulting in significant core idleness (NVIDIA's A100 introduced Sparse "
"Tensor Cores to mitigate this issue). In contrast, dataflow architectures—especially MIMD-based ones (e.g., Graphcore "
"IPU)—can flexibly schedule different tasks to different cores. The dataflow-driven execution model is naturally compatible with sparse computing, triggering computation only when data arrives, thus achieving higher energy efficiency."

#: ../../architecture_trends/significance.rst:232
msgid "工艺与封装"
msgstr "Process and Packaging"

#: ../../architecture_trends/significance.rst:234
msgid "**HBM + 先进封装：打破“内存墙”，实现存算一体**"
msgstr "**HBM + Advanced Packaging: Breaking the \"Memory Wall\" and Enabling Compute-Memory Integration**"

#: ../../architecture_trends/significance.rst:236
msgid "数据流架构的核心思想是让数据“流动”起来，尽可能减少计算单元因等待数据而产生的空闲。"
msgstr "The core idea of the dataflow architecture is to make data \"flow\", minimizing idleness of compute units caused by waiting for data."

#: ../../architecture_trends/significance.rst:238
msgid ""
"**HBM (高带宽内存)**：它通过3D堆叠技术将多个DRAM "
"die垂直堆叠起来，并通过极宽的接口（如1024-bit）与处理器通信。相比传统DDR内存几十GB/s的带宽，HBM可以轻松提供近1TB/s甚至更高的带宽。"
msgstr ""
"**HBM (High-Bandwidth Memory)**: It uses 3D stacking technology to vertically stack multiple DRAM dies "
"and communicates with the processor through an extremely wide interface (e.g., 1024-bit). Compared to the tens of GB/s bandwidth of traditional DDR memory, HBM can easily provide nearly 1TB/s or even higher bandwidth."

#: ../../architecture_trends/significance.rst:239
msgid ""
"**2.5D/3D封装**：这项技术是实现HBM与处理器紧密集成的关键。它不是将处理器和HBM芯片并排放在一块PCB板上，而是将它们都放置在一块被称为“硅中介层（Silicon"
" "
"Interposer）”的基板上（2.5D），或者直接将它们堆叠在一起（3D）。这种方式极大地缩短了二者之间的物理距离，从而实现了超高的带宽和更低的功耗。"
msgstr ""
"**2.5D/3D Packaging**: This technology is key to achieving tight integration between HBM and the processor. Instead of placing the processor and HBM chips side by side on a PCB, "
"they are both mounted on a substrate called a \"Silicon Interposer\" (2.5D) or directly stacked together (3D). This approach greatly shortens the physical distance between them, achieving ultra-high bandwidth and lower power consumption."

#: ../../architecture_trends/significance.rst:241
msgid "HBM和先进封装技术的结合，可以为数据流处理器配备了一个“贴身”的、容量和带宽都极高的内存资源，使得数据可以快速送达计算单元，物理上实现了“计算-存储”的紧耦合，这是数据流高效执行的基础。"
msgstr "The combination of HBM and advanced packaging technology equips dataflow processors with a \"dedicated\" memory resource featuring both high capacity and bandwidth, enabling rapid data delivery to compute units. This physically achieves tight coupling of \"compute and storage\", which is the foundation for efficient dataflow execution."

#: ../../architecture_trends/significance.rst:243
msgid "**Chiplet技术：构建超大规模AI芯片**"
msgstr "**Chiplet Technology: Building Ultra-Large-Scale AI Chips**"

#: ../../architecture_trends/significance.rst:245
msgid "随着AI模型越来越大，单块芯片的面积和功耗都逼近物理极限，制造成本也成为巨大挑战。Chiplet技术是将一个巨大的单片芯片拆分成多个功能独立的、更小的“芯粒”，再将它们封装在一起，协同工作。"
msgstr "As AI models grow larger, the area and power consumption of a single monolithic chip are approaching physical limits, and manufacturing costs have become a significant challenge. Chiplet technology involves splitting a large monolithic chip into multiple smaller, functionally independent \"chiplets\", which are then packaged together to work collaboratively."

#: ../../architecture_trends/significance.rst:247
msgid "**灵活性与成本效益**：不同的Chiplet可以用最适合它的工艺来制造。例如，计算单元可以用最先进的5nm/3nm工艺追求极致性能，而I/O接口则可以用成熟的16nm/22nm工艺来降低成本。这打破了单片芯片“一荣俱荣，一损俱损”的限制。"
msgstr "**Flexibility and Cost-Effectiveness**: Different chiplets can be manufactured using the most suitable process for their function. For example, compute units can use cutting-edge 5nm/3nm processes to pursue extreme performance, while I/O interfaces can use mature 16nm/22nm processes to reduce costs. This breaks the limitation of monolithic chips where \"success or failure is shared by all\"."

#: ../../architecture_trends/significance.rst:248
msgid ""
"**可扩展性 "
"(Scalability)**：这是Chiplet对数据流架构最重要的贡献。数据流架构天然适合并行扩展。借助Chiplet，厂商可以轻松地“按需组合”计算Chiplet、内存Chiplet和互联Chiplet，构建出规模远超单片芯片极限的AI加速器。例如，可以通过增加计算Chiplet的数量来线性提升算力。"
msgstr ""
"**Scalability**: "
"This is Chiplet's most important contribution to dataflow architectures. Dataflow architectures are naturally suited for parallel scaling. With Chiplets, manufacturers can easily \"assemble on demand\" compute chiplets, memory chiplets, and interconnection chiplets to build AI accelerators far exceeding the scale limits of monolithic chips. For example, computing power can be linearly increased by adding more compute chiplets."

#: ../../architecture_trends/significance.rst:249
msgid ""
"**专用的片上网络 (NoC)**：Chiplet之间需要高效的通信网络。这催生了专门的Die-to-"
"Die互联技术和高带宽的片上网络（NoC）。这与数据流架构中数据需要在不同处理单元间高效流动的需求不谋而合。Tenstorrent等公司正是利用了这一点，将每个Chiplet设计成一个独立的、带路由功能的节点，通过NoC将众多Chiplet连接成一个庞大的计算网络。"
msgstr ""
"**Dedicated Network-on-Chip (NoC)**: Efficient communication networks are required between chiplets. This has spurred the development of specialized Die-to-"
"Die interconnect technologies and high-bandwidth NoCs. This aligns perfectly with the dataflow architecture's need for efficient data flow between different processing units. Companies like Tenstorrent leverage this by designing each chiplet as an independent, routing-capable node, connecting numerous chiplets into a large-scale computing network via NoC."

#: ../../architecture_trends/significance.rst:251
msgid ""
"如果说HBM和先进封装解决了 **单个计算节点** 的内存带宽瓶颈，那么Chiplet技术则解决了 "
"**如何将成百上千个这样的节点高效扩展、连接成一个系统** 的难题。两者共同为数据流架构在AI时代大放异彩提供了坚实的硬件基础。"
msgstr ""
"If HBM and advanced packaging solve the memory bandwidth bottleneck of **individual compute nodes**, "
"then Chiplet technology solves the problem of **how to efficiently scale and connect hundreds or thousands of such nodes into a single system**. Together, they provide a solid hardware foundation for dataflow architectures to thrive in the AI era."

#: ../../architecture_trends/significance.rst:254
msgid "编译技术的发展"
msgstr "Development of Compilation Technology"

#: ../../architecture_trends/significance.rst:255
msgid ""
"**图编译器（Graph Compiler）的成熟**：以 "
"**MLIR**、XLA、TVM为代表的编译技术，能够将TensorFlow、PyTorch等框架定义的高层计算图，自动地、层次化地转换为底层的硬件指令。这使得数据流硬件复杂的映射、调度与优化过程可以由编译器自动完成，开发者无需直接面向底层硬件编程，极大地降低了数据流架构的使用门槛。"
msgstr ""
"**Maturity of Graph Compilers**: Compilation technologies represented by "
"**MLIR**, XLA, and TVM can automatically and hierarchically convert high-level computation graphs defined by frameworks such as TensorFlow and PyTorch into low-level hardware instructions. This allows the complex mapping, scheduling, and optimization processes of dataflow hardware to be automatically completed by the compiler, eliminating the need for developers to program directly for low-level hardware and greatly lowering the barrier to using dataflow architectures."

#: ../../architecture_trends/significance.rst:257
msgid "下面的示例展示了如何将一个简单的PyTorch模型导出为计算图，并交给TVM这类图编译器进行优化和生成特定硬件的可执行模块："
msgstr "The following example shows how to export a simple PyTorch model as a computation graph and pass it to a graph compiler like TVM for optimization and generation of executable modules for specific hardware:"

#: ../../architecture_trends/significance.rst:302
msgid ""
"在真实的数据流系统中，步骤 (1)～(4) "
"由编译器和运行时自动完成，开发者只需要在高层框架中定义模型即可，充分体现了图编译器在“降低数据流硬件使用门槛”上的作用。"
msgstr ""
"In a real-world dataflow system, steps (1)～(4) are automatically completed by the compiler and runtime. "
"Developers only need to define the model in a high-level framework, fully demonstrating the role of graph compilers in \"lowering the barrier to using dataflow hardware\"."